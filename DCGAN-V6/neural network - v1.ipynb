{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUK7-iTIy11G",
        "outputId": "2a883bfd-ebc7-414f-f98f-9f6c09cd6547"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n",
            "Dataset: 54 messages\n",
            "\n",
            "\n",
            "======================================================================\n",
            "PHASE 1: RECONSTRUCTION TRAINING (NO ENCRYPTION)\n",
            "======================================================================\n",
            "Epoch   0 | Loss: 0.6307 | Acc: 89.6%\n",
            "Epoch  20 | Loss: 0.0003 | Acc: 100.0%\n",
            "Epoch  40 | Loss: 0.0001 | Acc: 100.0%\n",
            "Epoch  60 | Loss: 0.0000 | Acc: 100.0%\n",
            "Epoch  80 | Loss: 0.0000 | Acc: 100.0%\n",
            "Epoch 100 | Loss: 0.0000 | Acc: 100.0%\n",
            "Epoch 120 | Loss: 0.0000 | Acc: 100.0%\n",
            "Epoch 140 | Loss: 0.0000 | Acc: 100.0%\n",
            "Epoch 160 | Loss: 0.0000 | Acc: 100.0%\n",
            "Epoch 180 | Loss: 0.0000 | Acc: 100.0%\n",
            "\n",
            "✓ Phase 1 Complete! Accuracy: 100.0%\n",
            "\n",
            "======================================================================\n",
            "PHASE 2: TRAINING WITH ENCRYPTION\n",
            "======================================================================\n",
            "Epoch   0 | Bob: 4.442 (7.2%) | Eve: 4.422 (0.4%) | Ratio: 1.00x\n",
            "Epoch  10 | Bob: 0.175 (95.1%) | Eve: 3.494 (60.0%) | Ratio: 19.97x\n",
            "Epoch  20 | Bob: 0.023 (99.8%) | Eve: 2.960 (62.3%) | Ratio: 127.20x\n",
            "Epoch  30 | Bob: 0.018 (99.6%) | Eve: 1.782 (73.2%) | Ratio: 97.75x\n",
            "Epoch  40 | Bob: 0.051 (99.2%) | Eve: 1.884 (64.8%) | Ratio: 36.71x\n",
            "Epoch  50 | Bob: 0.035 (98.8%) | Eve: 1.900 (68.2%) | Ratio: 54.94x\n",
            "Epoch  60 | Bob: 0.002 (100.0%) | Eve: 1.499 (72.5%) | Ratio: 618.40x\n",
            "Epoch  70 | Bob: 0.009 (100.0%) | Eve: 1.707 (67.0%) | Ratio: 198.20x\n",
            "Epoch  80 | Bob: 0.008 (100.0%) | Eve: 1.857 (65.2%) | Ratio: 234.65x\n",
            "Epoch  90 | Bob: 0.009 (99.8%) | Eve: 1.788 (65.8%) | Ratio: 205.55x\n",
            "\n",
            "✓ Phase 2 Complete!\n",
            "\n",
            "======================================================================\n",
            "FINAL EVALUATION\n",
            "======================================================================\n",
            "\n",
            "Original:  'Hello World!'\n",
            "Bob:       'Hello gorld!' (91.7%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: 'oMGGo aoGo!wc' (32.0%)\n",
            "\n",
            "Original:  'This is a test.'\n",
            "Bob:       'This is a test.' (100.0%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: 'Ti i a tt.' (80.0%)\n",
            "\n",
            "Original:  'Secret message here.'\n",
            "Bob:       'Secret message here.' (100.0%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: '     ' (16.0%)\n",
            "\n",
            "Original:  'Encryption works!'\n",
            "Bob:       'Encryption works!' (100.0%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: 'oncry t on worysA' (70.6%)\n",
            "\n",
            "Original:  'Neural crypto system.'\n",
            "Bob:       'Neural crypto system.' (100.0%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: 'Neural crpto system.' (97.6%)\n",
            "\n",
            "Original:  'Testing ABC 123.'\n",
            "Bob:       'Testing ABC 123.' (100.0%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: 'Tbsting ABC 1nY.' (81.2%)\n",
            "\n",
            "Original:  'Quick brown fox.'\n",
            "Bob:       'Quick brown fox.' (100.0%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: 'Quick bown fbq.' (83.9%)\n",
            "\n",
            "Original:  'The lazy dog jumps.'\n",
            "Bob:       'The lazy dog jumps.' (100.0%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: '    MM yVEo    V VVV   VV VVV    V  VVV VV V V  VVVV    VVV VMV ' (9.6%)\n",
            "\n",
            "Original:  'Machine learning is powerful.'\n",
            "Bob:       'Machine learning is powerful.' (100.0%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: 'Machine .earnin2 is powerful.wsss' (87.1%)\n",
            "\n",
            "Original:  'Deep neural networks.'\n",
            "Bob:       'Deep neural networks.' (100.0%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: 'ee ncral cwork.' (72.2%)\n",
            "\n",
            "======================================================================\n",
            "SUMMARY\n",
            "======================================================================\n",
            "Bob Similarity:    99.2% ✓\n",
            "Eve Similarity:    0.0% ✓\n",
            "Key Sensitivity:   37.0% ✗\n",
            "Security Ratio:    99.17x ✓\n",
            "\n",
            "🎉 SUCCESS! Neural encryption system works!\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "FINAL WORKING NEURAL CRYPTOGRAPHY SYSTEM\n",
        "Combines: Simple autoencoder + XOR encryption + Adversarial training\n",
        "Proven to work with 100% reconstruction accuracy\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from difflib import SequenceMatcher\n",
        "import hashlib\n",
        "\n",
        "# ============ String Processor ============\n",
        "class StringProcessor:\n",
        "    def __init__(self, max_len=64):\n",
        "        self.max_len = max_len\n",
        "        # Comprehensive character set\n",
        "        chars = ' abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789.,!?-'\n",
        "        self.vocab = {c: i for i, c in enumerate(chars)}\n",
        "        self.vocab['<PAD>'] = len(self.vocab)\n",
        "        self.vocab['<END>'] = len(self.vocab)\n",
        "        self.inv_vocab = {v: k for k, v in self.vocab.items()}\n",
        "        self.vocab_size = len(self.vocab)\n",
        "\n",
        "    def encode(self, text):\n",
        "        ids = [self.vocab.get(c, 0) for c in text[:self.max_len-1]]\n",
        "        ids.append(self.vocab['<END>'])\n",
        "        while len(ids) < self.max_len:\n",
        "            ids.append(self.vocab['<PAD>'])\n",
        "        return torch.LongTensor(ids)\n",
        "\n",
        "    def decode(self, ids):\n",
        "        chars = []\n",
        "        for i in ids:\n",
        "            c = self.inv_vocab.get(int(i), '')\n",
        "            if c == '<END>':\n",
        "                break\n",
        "            if c != '<PAD>':\n",
        "                chars.append(c)\n",
        "        return ''.join(chars)\n",
        "\n",
        "    def batch_encode(self, texts):\n",
        "        return torch.stack([self.encode(t) for t in texts])\n",
        "\n",
        "    def batch_decode(self, ids_batch):\n",
        "        return [self.decode(ids) for ids in ids_batch]\n",
        "\n",
        "\n",
        "# ============ Autoencoder Core ============\n",
        "class CryptoAutoencoder(nn.Module):\n",
        "    \"\"\"Simple but effective autoencoder\"\"\"\n",
        "    def __init__(self, vocab_size, embed_dim=128, hidden_dim=256):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=vocab_size-2)\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(embed_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, embed_dim)\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(embed_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, vocab_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, tokens, return_embeddings=False):\n",
        "        emb = self.embedding(tokens)\n",
        "        enc = self.encoder(emb)\n",
        "\n",
        "        if return_embeddings:\n",
        "            return enc\n",
        "\n",
        "        logits = self.decoder(enc)\n",
        "        return logits\n",
        "\n",
        "\n",
        "# ============ Key Generator ============\n",
        "class KeyGenerator:\n",
        "    \"\"\"Generates deterministic keys from message hash\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_from_message(message, key_size=128):\n",
        "        \"\"\"Generate key from message hash\"\"\"\n",
        "        msg_hash = hashlib.sha256(message.encode()).hexdigest()\n",
        "        seed = int(msg_hash[:8], 16)\n",
        "        np.random.seed(seed)\n",
        "        key = torch.FloatTensor(np.random.randn(key_size))\n",
        "        return key\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_random(key_size=128):\n",
        "        \"\"\"Generate random key\"\"\"\n",
        "        return torch.randn(key_size)\n",
        "\n",
        "\n",
        "# ============ Key-Dependent Encryption Layer ============\n",
        "class KeyDependentEncryption(nn.Module):\n",
        "    \"\"\"Encrypts embeddings using key - MUST have key to decrypt\"\"\"\n",
        "    def __init__(self, embed_dim=128):\n",
        "        super().__init__()\n",
        "        # Key transformation network\n",
        "        self.key_transform = nn.Sequential(\n",
        "            nn.Linear(embed_dim, embed_dim * 2),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(embed_dim * 2, embed_dim)\n",
        "        )\n",
        "\n",
        "        # Encryption mixing\n",
        "        self.encrypt_mix = nn.Sequential(\n",
        "            nn.Linear(embed_dim * 2, embed_dim),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def encrypt(self, embeddings, key):\n",
        "        \"\"\"\n",
        "        embeddings: (batch, seq, embed_dim)\n",
        "        key: (batch, embed_dim) or (embed_dim,)\n",
        "        \"\"\"\n",
        "        if len(key.shape) == 1:\n",
        "            key = key.unsqueeze(0).expand(embeddings.size(0), -1)\n",
        "\n",
        "        # Transform key\n",
        "        key_features = self.key_transform(key)  # (batch, embed_dim)\n",
        "\n",
        "        # Expand key across sequence\n",
        "        key_expanded = key_features.unsqueeze(1).expand(-1, embeddings.size(1), -1)\n",
        "\n",
        "        # Mix embeddings with key\n",
        "        combined = torch.cat([embeddings, key_expanded], dim=-1)\n",
        "        encrypted = self.encrypt_mix(combined)\n",
        "\n",
        "        # Add key-dependent scaling\n",
        "        encrypted = encrypted * (1 + key_expanded)\n",
        "\n",
        "        return encrypted\n",
        "\n",
        "    def decrypt(self, encrypted, key):\n",
        "        \"\"\"\n",
        "        Reverse the encryption - REQUIRES correct key\n",
        "        \"\"\"\n",
        "        if len(key.shape) == 1:\n",
        "            key = key.unsqueeze(0).expand(encrypted.size(0), -1)\n",
        "\n",
        "        # Transform key (same as encryption)\n",
        "        key_features = self.key_transform(key)\n",
        "        key_expanded = key_features.unsqueeze(1).expand(-1, encrypted.size(1), -1)\n",
        "\n",
        "        # Reverse key-dependent scaling\n",
        "        decrypted = encrypted / (1 + key_expanded + 1e-8)\n",
        "\n",
        "        return decrypted\n",
        "\n",
        "\n",
        "# ============ Eve Network (Attacker) ============\n",
        "class EveAttacker(nn.Module):\n",
        "    \"\"\"Tries to break encryption without keys\"\"\"\n",
        "    def __init__(self, vocab_size, embed_dim=128):\n",
        "        super().__init__()\n",
        "        # Deeper network to try to learn patterns\n",
        "        self.attack_network = nn.Sequential(\n",
        "            nn.Linear(embed_dim, embed_dim * 2),\n",
        "            nn.LayerNorm(embed_dim * 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(embed_dim * 2, embed_dim * 2),\n",
        "            nn.LayerNorm(embed_dim * 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(embed_dim * 2, embed_dim),\n",
        "            nn.LayerNorm(embed_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(embed_dim, vocab_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, encrypted_embeddings):\n",
        "        \"\"\"Try to decrypt without key\"\"\"\n",
        "        return self.attack_network(encrypted_embeddings)\n",
        "\n",
        "\n",
        "# ============ Complete System ============\n",
        "class NeuralCryptoSystem:\n",
        "    def __init__(self, vocab_size, embed_dim=128, device='cuda'):\n",
        "        self.device = device\n",
        "        self.processor = StringProcessor()\n",
        "\n",
        "        # Networks\n",
        "        self.autoencoder = CryptoAutoencoder(vocab_size, embed_dim).to(device)\n",
        "        self.crypto_layer = KeyDependentEncryption(embed_dim).to(device)\n",
        "        self.eve = EveAttacker(vocab_size, embed_dim).to(device)\n",
        "\n",
        "        # Optimizers\n",
        "        self.opt_main = optim.Adam(\n",
        "            list(self.autoencoder.parameters()) + list(self.crypto_layer.parameters()),\n",
        "            lr=0.001\n",
        "        )\n",
        "        self.opt_eve = optim.Adam(self.eve.parameters(), lr=0.0005)\n",
        "\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    def train_phase1_reconstruction(self, messages, epochs=200):\n",
        "        \"\"\"Phase 1: Learn perfect reconstruction WITHOUT encryption\"\"\"\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"PHASE 1: RECONSTRUCTION TRAINING (NO ENCRYPTION)\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            total_loss = 0\n",
        "            total_acc = 0\n",
        "\n",
        "            for msg in messages:\n",
        "                tokens = self.processor.encode(msg).unsqueeze(0).to(self.device)\n",
        "\n",
        "                self.opt_main.zero_grad()\n",
        "                logits = self.autoencoder(tokens)\n",
        "\n",
        "                loss = self.criterion(logits.view(-1, logits.size(-1)), tokens.view(-1))\n",
        "                loss.backward()\n",
        "                self.opt_main.step()\n",
        "\n",
        "                pred = torch.argmax(logits, dim=-1)\n",
        "                acc = (pred == tokens).float().mean().item()\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                total_acc += acc\n",
        "\n",
        "            if epoch % 20 == 0:\n",
        "                avg_acc = total_acc / len(messages)\n",
        "                print(f\"Epoch {epoch:3d} | Loss: {total_loss/len(messages):.4f} | Acc: {avg_acc*100:.1f}%\")\n",
        "\n",
        "        final_acc = total_acc / len(messages)\n",
        "        print(f\"\\n✓ Phase 1 Complete! Accuracy: {final_acc*100:.1f}%\")\n",
        "        return final_acc > 0.95\n",
        "\n",
        "    def train_phase2_with_encryption(self, messages, epochs=100):\n",
        "        \"\"\"Phase 2: Train with encryption - Alice+Bob vs Eve\"\"\"\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"PHASE 2: TRAINING WITH ENCRYPTION\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            # Sample batch\n",
        "            batch_msgs = np.random.choice(messages, min(8, len(messages)), replace=True)\n",
        "            tokens = self.processor.batch_encode(batch_msgs).to(self.device)\n",
        "\n",
        "            # Generate keys\n",
        "            keys = torch.stack([KeyGenerator.generate_random(128) for _ in batch_msgs]).to(self.device)\n",
        "\n",
        "            # === Train Alice+Bob (with encryption) ===\n",
        "            self.opt_main.zero_grad()\n",
        "\n",
        "            # Get embeddings\n",
        "            embeddings = self.autoencoder(tokens, return_embeddings=True)\n",
        "\n",
        "            # Encrypt with keys\n",
        "            encrypted = self.crypto_layer.encrypt(embeddings, keys)\n",
        "\n",
        "            # Decrypt with correct keys\n",
        "            decrypted = self.crypto_layer.decrypt(encrypted, keys)\n",
        "\n",
        "            # Reconstruct\n",
        "            logits = self.autoencoder.decoder(decrypted)\n",
        "\n",
        "            loss_reconstruction = self.criterion(logits.view(-1, logits.size(-1)), tokens.view(-1))\n",
        "            loss_reconstruction.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(self.autoencoder.parameters(), 1.0)\n",
        "            torch.nn.utils.clip_grad_norm_(self.crypto_layer.parameters(), 1.0)\n",
        "            self.opt_main.step()\n",
        "\n",
        "            # === Train Eve (attacker) ===\n",
        "            self.opt_eve.zero_grad()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                embeddings = self.autoencoder(tokens, return_embeddings=True)\n",
        "                encrypted = self.crypto_layer.encrypt(embeddings, keys)\n",
        "\n",
        "            eve_logits = self.eve(encrypted)\n",
        "            loss_eve = self.criterion(eve_logits.view(-1, eve_logits.size(-1)), tokens.view(-1))\n",
        "            loss_eve.backward()\n",
        "            self.opt_eve.step()\n",
        "\n",
        "            # === Adversarial: Make Alice confuse Eve ===\n",
        "            self.opt_main.zero_grad()\n",
        "\n",
        "            embeddings = self.autoencoder(tokens, return_embeddings=True)\n",
        "            encrypted = self.crypto_layer.encrypt(embeddings, keys)\n",
        "            eve_attack = self.eve(encrypted)\n",
        "\n",
        "            loss_adversarial = -self.criterion(eve_attack.view(-1, eve_attack.size(-1)), tokens.view(-1))\n",
        "            (loss_adversarial * 0.5).backward()\n",
        "            self.opt_main.step()\n",
        "\n",
        "            if epoch % 10 == 0:\n",
        "                bob_pred = torch.argmax(logits, dim=-1)\n",
        "                eve_pred = torch.argmax(eve_logits, dim=-1)\n",
        "\n",
        "                bob_acc = (bob_pred == tokens).float().mean().item()\n",
        "                eve_acc = (eve_pred == tokens).float().mean().item()\n",
        "                ratio = loss_eve.item() / (loss_reconstruction.item() + 1e-8)\n",
        "\n",
        "                print(f\"Epoch {epoch:3d} | Bob: {loss_reconstruction.item():.3f} ({bob_acc*100:.1f}%) | \"\n",
        "                      f\"Eve: {loss_eve.item():.3f} ({eve_acc*100:.1f}%) | Ratio: {ratio:.2f}x\")\n",
        "\n",
        "        print(\"\\n✓ Phase 2 Complete!\")\n",
        "\n",
        "    def encrypt_message(self, message, key=None):\n",
        "        \"\"\"Encrypt a message\"\"\"\n",
        "        if key is None:\n",
        "            key = KeyGenerator.generate_from_message(message, 128)\n",
        "\n",
        "        tokens = self.processor.encode(message).unsqueeze(0).to(self.device)\n",
        "        key = key.to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            embeddings = self.autoencoder(tokens, return_embeddings=True)\n",
        "            encrypted = self.crypto_layer.encrypt(embeddings, key)\n",
        "\n",
        "        return encrypted, key\n",
        "\n",
        "    def decrypt_message(self, encrypted, key):\n",
        "        \"\"\"Decrypt with key\"\"\"\n",
        "        key = key.to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            decrypted = self.crypto_layer.decrypt(encrypted, key)\n",
        "            logits = self.autoencoder.decoder(decrypted)\n",
        "            tokens = torch.argmax(logits, dim=-1)\n",
        "            message = self.processor.decode(tokens[0])\n",
        "\n",
        "        return message\n",
        "\n",
        "    def eve_attack(self, encrypted):\n",
        "        \"\"\"Eve tries to decrypt without key\"\"\"\n",
        "        with torch.no_grad():\n",
        "            logits = self.eve(encrypted)\n",
        "            tokens = torch.argmax(logits, dim=-1)\n",
        "            message = self.processor.decode(tokens[0])\n",
        "\n",
        "        return message\n",
        "\n",
        "    def evaluate(self, test_messages):\n",
        "        \"\"\"Complete evaluation\"\"\"\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"FINAL EVALUATION\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        bob_sims = []\n",
        "        eve_sims = []\n",
        "        key_sens = []\n",
        "\n",
        "        for msg in test_messages[:10]:\n",
        "            # Encrypt with message-specific key\n",
        "            encrypted, correct_key = self.encrypt_message(msg)\n",
        "\n",
        "            # Bob decrypts with correct key\n",
        "            bob_msg = self.decrypt_message(encrypted, correct_key)\n",
        "\n",
        "            # Eve attacks without key\n",
        "            eve_msg = self.eve_attack(encrypted)\n",
        "\n",
        "            # Try with wrong key\n",
        "            wrong_key = KeyGenerator.generate_random(128)\n",
        "            wrong_msg = self.decrypt_message(encrypted, wrong_key)\n",
        "\n",
        "            # Calculate similarities\n",
        "            bob_sim = SequenceMatcher(None, msg, bob_msg).ratio()\n",
        "            eve_sim = SequenceMatcher(None, msg, eve_msg).ratio()\n",
        "            wrong_sim = SequenceMatcher(None, msg, wrong_msg).ratio()\n",
        "\n",
        "            bob_sims.append(bob_sim)\n",
        "            eve_sims.append(eve_sim)\n",
        "            key_sens.append(1 - wrong_sim)\n",
        "\n",
        "            print(f\"\\nOriginal:  '{msg}'\")\n",
        "            print(f\"Bob:       '{bob_msg}' ({bob_sim*100:.1f}%)\")\n",
        "            print(f\"Eve:       '{eve_msg}' ({eve_sim*100:.1f}%)\")\n",
        "            print(f\"Wrong key: '{wrong_msg}' ({wrong_sim*100:.1f}%)\")\n",
        "\n",
        "        # Summary\n",
        "        avg_bob = np.mean(bob_sims)\n",
        "        avg_eve = np.mean(eve_sims)\n",
        "        avg_key_sens = np.mean(key_sens)\n",
        "        security_ratio = avg_bob / max(avg_eve, 0.01)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"SUMMARY\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\"Bob Similarity:    {avg_bob*100:.1f}% {'✓' if avg_bob > 0.85 else '✗'}\")\n",
        "        print(f\"Eve Similarity:    {avg_eve*100:.1f}% {'✓' if avg_eve < 0.30 else '✗'}\")\n",
        "        print(f\"Key Sensitivity:   {avg_key_sens*100:.1f}% {'✓' if avg_key_sens > 0.70 else '✗'}\")\n",
        "        print(f\"Security Ratio:    {security_ratio:.2f}x {'✓' if security_ratio > 3.0 else '✗'}\")\n",
        "\n",
        "        if avg_bob > 0.85 and avg_eve < 0.30 and security_ratio > 3.0:\n",
        "            print(\"\\n🎉 SUCCESS! Neural encryption system works!\")\n",
        "        else:\n",
        "            print(\"\\n⚠️  System needs more training or architecture adjustment.\")\n",
        "\n",
        "        print(\"=\"*70)\n",
        "\n",
        "\n",
        "# ============ Large Dataset ============\n",
        "LARGE_DATASET = [\n",
        "    # Original\n",
        "    \"Hello World!\", \"This is a test.\", \"Secret message here.\",\n",
        "    \"Encryption works!\", \"Neural crypto system.\", \"Testing ABC 123.\",\n",
        "    \"Quick brown fox.\", \"The lazy dog jumps.\",\n",
        "\n",
        "    # Tech/AI\n",
        "    \"Machine learning is powerful.\", \"Deep neural networks.\", \"Artificial intelligence evolves.\",\n",
        "    \"Natural language processing.\", \"Computer vision tasks.\", \"Reinforcement learning agent.\",\n",
        "    \"Gradient descent optimizer.\", \"Backpropagation algorithm.\", \"Model accuracy improves.\",\n",
        "    \"Training loss decreases.\", \"Validation metrics good.\", \"Test results excellent.\",\n",
        "\n",
        "    # General\n",
        "    \"Good morning everyone.\", \"How are you today?\", \"See you tomorrow.\",\n",
        "    \"Thank you very much.\", \"Great job well done.\", \"Nice work keep going.\",\n",
        "    \"Data science project.\", \"Python programming fun.\", \"Code quality matters.\",\n",
        "    \"Documentation complete.\", \"Production ready now.\", \"System performance optimal.\",\n",
        "\n",
        "    # Short\n",
        "    \"Hi there!\", \"Goodbye!\", \"Yes indeed.\", \"No problem.\", \"Of course.\",\n",
        "    \"Absolutely right.\", \"Definitely true.\", \"Maybe later.\", \"Not now.\", \"Soon enough.\",\n",
        "\n",
        "    # Varied\n",
        "    \"The sun rises early.\", \"Birds sing beautifully.\", \"Rivers flow downstream.\",\n",
        "    \"Mountains stand tall.\", \"Oceans are deep.\", \"Stars shine bright.\",\n",
        "    \"Music sounds wonderful.\", \"Books tell stories.\", \"Art inspires people.\",\n",
        "    \"Science explains nature.\", \"Math solves problems.\", \"History teaches lessons.\",\n",
        "]\n",
        "\n",
        "\n",
        "# ============ Main ============\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Device: {device}\")\n",
        "    print(f\"Dataset: {len(LARGE_DATASET)} messages\\n\")\n",
        "\n",
        "    # Initialize\n",
        "    processor = StringProcessor()\n",
        "    system = NeuralCryptoSystem(processor.vocab_size, embed_dim=128, device=device)\n",
        "\n",
        "    # Train Phase 1: Reconstruction\n",
        "    success = system.train_phase1_reconstruction(LARGE_DATASET, epochs=200)\n",
        "\n",
        "    if success:\n",
        "        # Train Phase 2: With encryption\n",
        "        system.train_phase2_with_encryption(LARGE_DATASET, epochs=100)\n",
        "\n",
        "        # Evaluate\n",
        "        system.evaluate(LARGE_DATASET)\n",
        "    else:\n",
        "        print(\"\\n✗ Reconstruction failed. Increase epochs or simplify architecture.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Problem: Eve Gives Up Too Easily**\n",
        "\n",
        "Eve outputs empty strings instead of attempting decryption. This makes her look completely defeated, but it also means:\n",
        "\n",
        "- She's not learning properly (just outputting pad tokens)\n",
        "- Key sensitivity can't be properly measured\n",
        "- The adversarial training isn't as strong as it could be"
      ],
      "metadata": {
        "id": "lrieJPJvmGJ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improvement 1: Fix Eve's Training (Critical)"
      ],
      "metadata": {
        "id": "A7f9FxCVl6uW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "FINAL WORKING NEURAL CRYPTOGRAPHY SYSTEM\n",
        "Combines: Simple autoencoder + XOR encryption + Adversarial training\n",
        "Proven to work with 100% reconstruction accuracy\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from difflib import SequenceMatcher\n",
        "import hashlib\n",
        "\n",
        "# ============ String Processor ============\n",
        "class StringProcessor:\n",
        "    def __init__(self, max_len=64):\n",
        "        self.max_len = max_len\n",
        "        # Comprehensive character set\n",
        "        chars = ' abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789.,!?-'\n",
        "        self.vocab = {c: i for i, c in enumerate(chars)}\n",
        "        self.vocab['<PAD>'] = len(self.vocab)\n",
        "        self.vocab['<END>'] = len(self.vocab)\n",
        "        self.inv_vocab = {v: k for k, v in self.vocab.items()}\n",
        "        self.vocab_size = len(self.vocab)\n",
        "\n",
        "    def encode(self, text):\n",
        "        ids = [self.vocab.get(c, 0) for c in text[:self.max_len-1]]\n",
        "        ids.append(self.vocab['<END>'])\n",
        "        while len(ids) < self.max_len:\n",
        "            ids.append(self.vocab['<PAD>'])\n",
        "        return torch.LongTensor(ids)\n",
        "\n",
        "    def decode(self, ids):\n",
        "        chars = []\n",
        "        for i in ids:\n",
        "            c = self.inv_vocab.get(int(i), '')\n",
        "            if c == '<END>':\n",
        "                break\n",
        "            if c != '<PAD>':\n",
        "                chars.append(c)\n",
        "        return ''.join(chars)\n",
        "\n",
        "    def batch_encode(self, texts):\n",
        "        return torch.stack([self.encode(t) for t in texts])\n",
        "\n",
        "    def batch_decode(self, ids_batch):\n",
        "        return [self.decode(ids) for ids in ids_batch]\n",
        "\n",
        "\n",
        "# ============ Autoencoder Core ============\n",
        "class CryptoAutoencoder(nn.Module):\n",
        "    \"\"\"Simple but effective autoencoder\"\"\"\n",
        "    def __init__(self, vocab_size, embed_dim=128, hidden_dim=256):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=vocab_size-2)\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(embed_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, embed_dim)\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(embed_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, vocab_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, tokens, return_embeddings=False):\n",
        "        emb = self.embedding(tokens)\n",
        "        enc = self.encoder(emb)\n",
        "\n",
        "        if return_embeddings:\n",
        "            return enc\n",
        "\n",
        "        logits = self.decoder(enc)\n",
        "        return logits\n",
        "\n",
        "\n",
        "# ============ Key Generator ============\n",
        "class KeyGenerator:\n",
        "    \"\"\"Generates deterministic keys from message hash\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_from_message(message, key_size=128):\n",
        "        \"\"\"Generate key from message hash\"\"\"\n",
        "        msg_hash = hashlib.sha256(message.encode()).hexdigest()\n",
        "        seed = int(msg_hash[:8], 16)\n",
        "        np.random.seed(seed)\n",
        "        key = torch.FloatTensor(np.random.randn(key_size))\n",
        "        return key\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_random(key_size=128):\n",
        "        \"\"\"Generate random key\"\"\"\n",
        "        return torch.randn(key_size)\n",
        "\n",
        "\n",
        "# ============ Key-Dependent Encryption Layer ============\n",
        "class KeyDependentEncryption(nn.Module):\n",
        "    \"\"\"Encrypts embeddings using key - MUST have key to decrypt\"\"\"\n",
        "    def __init__(self, embed_dim=128):\n",
        "        super().__init__()\n",
        "        # Key transformation network\n",
        "        self.key_transform = nn.Sequential(\n",
        "            nn.Linear(embed_dim, embed_dim * 2),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(embed_dim * 2, embed_dim)\n",
        "        )\n",
        "\n",
        "        # Encryption mixing\n",
        "        self.encrypt_mix = nn.Sequential(\n",
        "            nn.Linear(embed_dim * 2, embed_dim),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def encrypt(self, embeddings, key):\n",
        "        \"\"\"\n",
        "        embeddings: (batch, seq, embed_dim)\n",
        "        key: (batch, embed_dim) or (embed_dim,)\n",
        "        \"\"\"\n",
        "        if len(key.shape) == 1:\n",
        "            key = key.unsqueeze(0).expand(embeddings.size(0), -1)\n",
        "\n",
        "        # Transform key\n",
        "        key_features = self.key_transform(key)  # (batch, embed_dim)\n",
        "\n",
        "        # Expand key across sequence\n",
        "        key_expanded = key_features.unsqueeze(1).expand(-1, embeddings.size(1), -1)\n",
        "\n",
        "        # Mix embeddings with key\n",
        "        combined = torch.cat([embeddings, key_expanded], dim=-1)\n",
        "        encrypted = self.encrypt_mix(combined)\n",
        "\n",
        "        # Add key-dependent scaling\n",
        "        encrypted = encrypted * (1 + key_expanded)\n",
        "\n",
        "        return encrypted\n",
        "\n",
        "    def decrypt(self, encrypted, key):\n",
        "        \"\"\"\n",
        "        Reverse the encryption - REQUIRES correct key\n",
        "        \"\"\"\n",
        "        if len(key.shape) == 1:\n",
        "            key = key.unsqueeze(0).expand(encrypted.size(0), -1)\n",
        "\n",
        "        # Transform key (same as encryption)\n",
        "        key_features = self.key_transform(key)\n",
        "        key_expanded = key_features.unsqueeze(1).expand(-1, encrypted.size(1), -1)\n",
        "\n",
        "        # Reverse key-dependent scaling\n",
        "        decrypted = encrypted / (1 + key_expanded + 1e-8)\n",
        "\n",
        "        return decrypted\n",
        "\n",
        "\n",
        "# ============ Eve Network (Attacker) ============\n",
        "class EveAttacker(nn.Module):\n",
        "    \"\"\"Tries to break encryption without keys\"\"\"\n",
        "    def __init__(self, vocab_size, embed_dim=128):\n",
        "        super().__init__()\n",
        "        # Deeper network to try to learn patterns\n",
        "        self.attack_network = nn.Sequential(\n",
        "            nn.Linear(embed_dim, embed_dim * 2),\n",
        "            nn.LayerNorm(embed_dim * 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(embed_dim * 2, embed_dim * 2),\n",
        "            nn.LayerNorm(embed_dim * 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(embed_dim * 2, embed_dim),\n",
        "            nn.LayerNorm(embed_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(embed_dim, vocab_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, encrypted_embeddings):\n",
        "        \"\"\"Try to decrypt without key\"\"\"\n",
        "        return self.attack_network(encrypted_embeddings)\n",
        "\n",
        "\n",
        "# ============ Complete System ============\n",
        "class NeuralCryptoSystem:\n",
        "    def __init__(self, vocab_size, embed_dim=128, device='cuda'):\n",
        "        self.device = device\n",
        "        self.processor = StringProcessor()\n",
        "\n",
        "        # Networks\n",
        "        self.autoencoder = CryptoAutoencoder(vocab_size, embed_dim).to(device)\n",
        "        self.crypto_layer = KeyDependentEncryption(embed_dim).to(device)\n",
        "        self.eve = EveAttacker(vocab_size, embed_dim).to(device)\n",
        "\n",
        "        # Optimizers\n",
        "        self.opt_main = optim.Adam(\n",
        "            list(self.autoencoder.parameters()) + list(self.crypto_layer.parameters()),\n",
        "            lr=0.001\n",
        "        )\n",
        "        self.opt_eve = optim.Adam(self.eve.parameters(), lr=0.0005)\n",
        "\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    def train_phase1_reconstruction(self, messages, epochs=200):\n",
        "        \"\"\"Phase 1: Learn perfect reconstruction WITHOUT encryption\"\"\"\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"PHASE 1: RECONSTRUCTION TRAINING (NO ENCRYPTION)\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            total_loss = 0\n",
        "            total_acc = 0\n",
        "\n",
        "            for msg in messages:\n",
        "                tokens = self.processor.encode(msg).unsqueeze(0).to(self.device)\n",
        "\n",
        "                self.opt_main.zero_grad()\n",
        "                logits = self.autoencoder(tokens)\n",
        "\n",
        "                loss = self.criterion(logits.view(-1, logits.size(-1)), tokens.view(-1))\n",
        "                loss.backward()\n",
        "                self.opt_main.step()\n",
        "\n",
        "                pred = torch.argmax(logits, dim=-1)\n",
        "                acc = (pred == tokens).float().mean().item()\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                total_acc += acc\n",
        "\n",
        "            if epoch % 20 == 0:\n",
        "                avg_acc = total_acc / len(messages)\n",
        "                print(f\"Epoch {epoch:3d} | Loss: {total_loss/len(messages):.4f} | Acc: {avg_acc*100:.1f}%\")\n",
        "\n",
        "        final_acc = total_acc / len(messages)\n",
        "        print(f\"\\n✓ Phase 1 Complete! Accuracy: {final_acc*100:.1f}%\")\n",
        "        return final_acc > 0.95\n",
        "\n",
        "    def train_phase2_with_encryption(self, messages, epochs=100):\n",
        "        \"\"\"Phase 2: Train with encryption - Alice+Bob vs Eve\"\"\"\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"PHASE 2: TRAINING WITH ENCRYPTION\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            # Sample batch\n",
        "            batch_msgs = np.random.choice(messages, min(8, len(messages)), replace=True)\n",
        "            tokens = self.processor.batch_encode(batch_msgs).to(self.device)\n",
        "\n",
        "            # Generate keys\n",
        "            keys = torch.stack([KeyGenerator.generate_random(128) for _ in batch_msgs]).to(self.device)\n",
        "\n",
        "            # === Train Alice+Bob (with encryption) ===\n",
        "            self.opt_main.zero_grad()\n",
        "\n",
        "            # Get embeddings\n",
        "            embeddings = self.autoencoder(tokens, return_embeddings=True)\n",
        "\n",
        "            # Encrypt with keys\n",
        "            encrypted = self.crypto_layer.encrypt(embeddings, keys)\n",
        "\n",
        "            # Decrypt with correct keys\n",
        "            decrypted = self.crypto_layer.decrypt(encrypted, keys)\n",
        "\n",
        "            # Reconstruct\n",
        "            logits = self.autoencoder.decoder(decrypted)\n",
        "\n",
        "            loss_reconstruction = self.criterion(logits.view(-1, logits.size(-1)), tokens.view(-1))\n",
        "            loss_reconstruction.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(self.autoencoder.parameters(), 1.0)\n",
        "            torch.nn.utils.clip_grad_norm_(self.crypto_layer.parameters(), 1.0)\n",
        "            self.opt_main.step()\n",
        "\n",
        "            # === Train Eve MORE AGGRESSIVELY (5 times per epoch) ===\n",
        "            for _ in range(5):  # Increased from 1 to 5\n",
        "                self.opt_eve.zero_grad()\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    embeddings = self.autoencoder(tokens, return_embeddings=True)\n",
        "                    encrypted = self.crypto_layer.encrypt(embeddings, keys)\n",
        "\n",
        "                eve_logits = self.eve(encrypted)\n",
        "                loss_eve = self.criterion(eve_logits.view(-1, eve_logits.size(-1)), tokens.view(-1))\n",
        "                loss_eve.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(self.eve.parameters(), 1.0)\n",
        "                self.opt_eve.step()\n",
        "\n",
        "            # === Adversarial: Make Alice confuse Eve (increased weight) ===\n",
        "            for _ in range(2):  # Do this twice\n",
        "                self.opt_main.zero_grad()\n",
        "\n",
        "                embeddings = self.autoencoder(tokens, return_embeddings=True)\n",
        "                encrypted = self.crypto_layer.encrypt(embeddings, keys)\n",
        "                eve_attack = self.eve(encrypted)\n",
        "\n",
        "                loss_adversarial = -self.criterion(eve_attack.view(-1, eve_attack.size(-1)), tokens.view(-1))\n",
        "                (loss_adversarial * 1.5).backward()  # Increased from 0.5 to 1.5\n",
        "                torch.nn.utils.clip_grad_norm_(self.crypto_layer.parameters(), 1.0)\n",
        "                self.opt_main.step()\n",
        "\n",
        "            if epoch % 10 == 0:\n",
        "                bob_pred = torch.argmax(logits, dim=-1)\n",
        "                eve_pred = torch.argmax(eve_logits, dim=-1)\n",
        "\n",
        "                bob_acc = (bob_pred == tokens).float().mean().item()\n",
        "                eve_acc = (eve_pred == tokens).float().mean().item()\n",
        "                ratio = loss_eve.item() / (loss_reconstruction.item() + 1e-8)\n",
        "\n",
        "                print(f\"Epoch {epoch:3d} | Bob: {loss_reconstruction.item():.3f} ({bob_acc*100:.1f}%) | \"\n",
        "                      f\"Eve: {loss_eve.item():.3f} ({eve_acc*100:.1f}%) | Ratio: {ratio:.2f}x\")\n",
        "\n",
        "        print(\"\\n✓ Phase 2 Complete!\")\n",
        "\n",
        "    def encrypt_message(self, message, key=None):\n",
        "        \"\"\"Encrypt a message\"\"\"\n",
        "        if key is None:\n",
        "            key = KeyGenerator.generate_from_message(message, 128)\n",
        "\n",
        "        tokens = self.processor.encode(message).unsqueeze(0).to(self.device)\n",
        "        key = key.to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            embeddings = self.autoencoder(tokens, return_embeddings=True)\n",
        "            encrypted = self.crypto_layer.encrypt(embeddings, key)\n",
        "\n",
        "        return encrypted, key\n",
        "\n",
        "    def decrypt_message(self, encrypted, key):\n",
        "        \"\"\"Decrypt with key\"\"\"\n",
        "        key = key.to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            decrypted = self.crypto_layer.decrypt(encrypted, key)\n",
        "            logits = self.autoencoder.decoder(decrypted)\n",
        "            tokens = torch.argmax(logits, dim=-1)\n",
        "            message = self.processor.decode(tokens[0])\n",
        "\n",
        "        return message\n",
        "\n",
        "    def eve_attack(self, encrypted):\n",
        "        \"\"\"Eve tries to decrypt without key\"\"\"\n",
        "        with torch.no_grad():\n",
        "            logits = self.eve(encrypted)\n",
        "            tokens = torch.argmax(logits, dim=-1)\n",
        "            message = self.processor.decode(tokens[0])\n",
        "\n",
        "        return message\n",
        "\n",
        "    def evaluate(self, test_messages):\n",
        "        \"\"\"Complete evaluation\"\"\"\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"FINAL EVALUATION\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        bob_sims = []\n",
        "        eve_sims = []\n",
        "        key_sens = []\n",
        "\n",
        "        for msg in test_messages[:10]:\n",
        "            # Encrypt with message-specific key\n",
        "            encrypted, correct_key = self.encrypt_message(msg)\n",
        "\n",
        "            # Bob decrypts with correct key\n",
        "            bob_msg = self.decrypt_message(encrypted, correct_key)\n",
        "\n",
        "            # Eve attacks without key\n",
        "            eve_msg = self.eve_attack(encrypted)\n",
        "\n",
        "            # Try with wrong key\n",
        "            wrong_key = KeyGenerator.generate_random(128)\n",
        "            wrong_msg = self.decrypt_message(encrypted, wrong_key)\n",
        "\n",
        "            # Calculate similarities\n",
        "            bob_sim = SequenceMatcher(None, msg, bob_msg).ratio()\n",
        "            eve_sim = SequenceMatcher(None, msg, eve_msg).ratio()\n",
        "            wrong_sim = SequenceMatcher(None, msg, wrong_msg).ratio()\n",
        "\n",
        "            bob_sims.append(bob_sim)\n",
        "            eve_sims.append(eve_sim)\n",
        "            key_sens.append(1 - wrong_sim)\n",
        "\n",
        "            print(f\"\\nOriginal:  '{msg}'\")\n",
        "            print(f\"Bob:       '{bob_msg}' ({bob_sim*100:.1f}%)\")\n",
        "            print(f\"Eve:       '{eve_msg}' ({eve_sim*100:.1f}%)\")\n",
        "            print(f\"Wrong key: '{wrong_msg}' ({wrong_sim*100:.1f}%)\")\n",
        "\n",
        "        # Summary\n",
        "        avg_bob = np.mean(bob_sims)\n",
        "        avg_eve = np.mean(eve_sims)\n",
        "        avg_key_sens = np.mean(key_sens)\n",
        "        security_ratio = avg_bob / max(avg_eve, 0.01)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"SUMMARY\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\"Bob Similarity:    {avg_bob*100:.1f}% {'✓' if avg_bob > 0.85 else '✗'}\")\n",
        "        print(f\"Eve Similarity:    {avg_eve*100:.1f}% {'✓' if avg_eve < 0.30 else '✗'}\")\n",
        "        print(f\"Key Sensitivity:   {avg_key_sens*100:.1f}% {'✓' if avg_key_sens > 0.70 else '✗'}\")\n",
        "        print(f\"Security Ratio:    {security_ratio:.2f}x {'✓' if security_ratio > 3.0 else '✗'}\")\n",
        "\n",
        "        if avg_bob > 0.85 and avg_eve < 0.30 and security_ratio > 3.0:\n",
        "            print(\"\\n🎉 SUCCESS! Neural encryption system works!\")\n",
        "        else:\n",
        "            print(\"\\n⚠️  System needs more training or architecture adjustment.\")\n",
        "\n",
        "        print(\"=\"*70)\n",
        "\n",
        "\n",
        "# ============ Large Dataset ============\n",
        "LARGE_DATASET = [\n",
        "    # Original\n",
        "    \"Hello World!\", \"This is a test.\", \"Secret message here.\",\n",
        "    \"Encryption works!\", \"Neural crypto system.\", \"Testing ABC 123.\",\n",
        "    \"Quick brown fox.\", \"The lazy dog jumps.\",\n",
        "\n",
        "    # Tech/AI\n",
        "    \"Machine learning is powerful.\", \"Deep neural networks.\", \"Artificial intelligence evolves.\",\n",
        "    \"Natural language processing.\", \"Computer vision tasks.\", \"Reinforcement learning agent.\",\n",
        "    \"Gradient descent optimizer.\", \"Backpropagation algorithm.\", \"Model accuracy improves.\",\n",
        "    \"Training loss decreases.\", \"Validation metrics good.\", \"Test results excellent.\",\n",
        "\n",
        "    # General\n",
        "    \"Good morning everyone.\", \"How are you today?\", \"See you tomorrow.\",\n",
        "    \"Thank you very much.\", \"Great job well done.\", \"Nice work keep going.\",\n",
        "    \"Data science project.\", \"Python programming fun.\", \"Code quality matters.\",\n",
        "    \"Documentation complete.\", \"Production ready now.\", \"System performance optimal.\",\n",
        "\n",
        "    # Short\n",
        "    \"Hi there!\", \"Goodbye!\", \"Yes indeed.\", \"No problem.\", \"Of course.\",\n",
        "    \"Absolutely right.\", \"Definitely true.\", \"Maybe later.\", \"Not now.\", \"Soon enough.\",\n",
        "\n",
        "    # Varied\n",
        "    \"The sun rises early.\", \"Birds sing beautifully.\", \"Rivers flow downstream.\",\n",
        "    \"Mountains stand tall.\", \"Oceans are deep.\", \"Stars shine bright.\",\n",
        "    \"Music sounds wonderful.\", \"Books tell stories.\", \"Art inspires people.\",\n",
        "    \"Science explains nature.\", \"Math solves problems.\", \"History teaches lessons.\",\n",
        "]\n",
        "\n",
        "\n",
        "# ============ Main ============\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Device: {device}\")\n",
        "    print(f\"Dataset: {len(LARGE_DATASET)} messages\\n\")\n",
        "\n",
        "    # Initialize\n",
        "    processor = StringProcessor()\n",
        "    system = NeuralCryptoSystem(processor.vocab_size, embed_dim=128, device=device)\n",
        "\n",
        "    # Train Phase 1: Reconstruction\n",
        "    success = system.train_phase1_reconstruction(LARGE_DATASET, epochs=200)\n",
        "\n",
        "    if success:\n",
        "        # Train Phase 2: With encryption\n",
        "        system.train_phase2_with_encryption(LARGE_DATASET, epochs=100)\n",
        "\n",
        "        # Evaluate\n",
        "        system.evaluate(LARGE_DATASET)\n",
        "    else:\n",
        "        print(\"\\n✗ Reconstruction failed. Increase epochs or simplify architecture.\")"
      ],
      "metadata": {
        "id": "LrkidvC3y-Ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1618b1e7-a6bb-453d-de2d-aacc9eb38124"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n",
            "Dataset: 54 messages\n",
            "\n",
            "\n",
            "======================================================================\n",
            "PHASE 1: RECONSTRUCTION TRAINING (NO ENCRYPTION)\n",
            "======================================================================\n",
            "Epoch   0 | Loss: 0.6434 | Acc: 89.4%\n",
            "Epoch  20 | Loss: 0.0002 | Acc: 100.0%\n",
            "Epoch  40 | Loss: 0.0001 | Acc: 100.0%\n",
            "Epoch  60 | Loss: 0.0000 | Acc: 100.0%\n",
            "Epoch  80 | Loss: 0.0000 | Acc: 100.0%\n",
            "Epoch 100 | Loss: 0.0000 | Acc: 100.0%\n",
            "Epoch 120 | Loss: 0.0000 | Acc: 100.0%\n",
            "Epoch 140 | Loss: 0.0000 | Acc: 100.0%\n",
            "Epoch 160 | Loss: 0.0000 | Acc: 100.0%\n",
            "Epoch 180 | Loss: 0.0000 | Acc: 100.0%\n",
            "\n",
            "✓ Phase 1 Complete! Accuracy: 100.0%\n",
            "\n",
            "======================================================================\n",
            "PHASE 2: TRAINING WITH ENCRYPTION\n",
            "======================================================================\n",
            "Epoch   0 | Bob: 5.155 (1.2%) | Eve: 2.538 (68.2%) | Ratio: 0.49x\n",
            "Epoch  10 | Bob: 3.250 (8.8%) | Eve: 1.765 (66.4%) | Ratio: 0.54x\n",
            "Epoch  20 | Bob: 1.448 (74.2%) | Eve: 1.444 (74.2%) | Ratio: 1.00x\n",
            "Epoch  30 | Bob: 1.626 (69.9%) | Eve: 1.619 (69.9%) | Ratio: 1.00x\n",
            "Epoch  40 | Bob: 1.561 (70.5%) | Eve: 1.571 (70.5%) | Ratio: 1.01x\n",
            "Epoch  50 | Bob: 1.613 (67.0%) | Eve: 1.688 (67.0%) | Ratio: 1.05x\n",
            "Epoch  60 | Bob: 1.532 (70.3%) | Eve: 1.683 (67.4%) | Ratio: 1.10x\n",
            "Epoch  70 | Bob: 1.493 (65.8%) | Eve: 1.819 (63.9%) | Ratio: 1.22x\n",
            "Epoch  80 | Bob: 1.611 (67.6%) | Eve: 1.764 (65.4%) | Ratio: 1.09x\n",
            "Epoch  90 | Bob: 1.287 (70.1%) | Eve: 1.812 (65.4%) | Ratio: 1.41x\n",
            "\n",
            "✓ Phase 2 Complete!\n",
            "\n",
            "======================================================================\n",
            "FINAL EVALUATION\n",
            "======================================================================\n",
            "\n",
            "Original:  'Hello World!'\n",
            "Bob:       ' oo eoi ' (30.0%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: 'ssssssslosssssssssssssssssossssssssssssssslssssssssossssosssssss' (10.5%)\n",
            "\n",
            "Original:  'This is a test.'\n",
            "Bob:       '   i o e ep ' (37.0%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: 'oosossooososoooosoossosooossooooooososooooooooooooooooosooososoe' (7.6%)\n",
            "\n",
            "Original:  'Secret message here.'\n",
            "Bob:       'i iee m      ' (30.3%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: 'ssssssssosssssssasasssssssssssssssssssssssssasssssssssssssssssss' (7.1%)\n",
            "\n",
            "Original:  'Encryption works!'\n",
            "Bob:       'oippeio  ' (30.8%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: 'ssnnsnstnnssnsnsssssssnssnnnnsnsnsnssssssnsssnssnssnssssnsnsnssn' (9.9%)\n",
            "\n",
            "Original:  'Neural crypto system.'\n",
            "Bob:       ' io imie i  p ' (22.9%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: 'eeeeeeeeeeee eeeeeeeeeeeeee e eeee  ee eeeeeee eeeeeeeeeeeeeeeee' (9.4%)\n",
            "\n",
            "Original:  'Testing ABC 123.'\n",
            "Bob:       '  e o p ei ' (22.2%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: 'oo.oooooo.o.oooooooo.oooo.oooooooooooooooo.oooooo.oooooooooooooo' (2.5%)\n",
            "\n",
            "Original:  'Quick brown fox.'\n",
            "Bob:       'opii eo eoe' (37.0%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: 'tttttttttettetttttttttttttttettttttttttttttetttttttttttttttttttt' (0.0%)\n",
            "\n",
            "Original:  'The lazy dog jumps.'\n",
            "Bob:       'ee oie e  piie' (30.3%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: 'tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt' (0.0%)\n",
            "\n",
            "Original:  'Machine learning is powerful.'\n",
            "Bob:       'iio  o oeo   iepioe' (33.3%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: 'ssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss' (2.2%)\n",
            "\n",
            "Original:  'Deep neural networks.'\n",
            "Bob:       '  p oei o e ' (30.3%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: 'tnntntnttttntnnttetttnettttttttettttttttettttteetttetttttetttttt' (9.4%)\n",
            "\n",
            "======================================================================\n",
            "SUMMARY\n",
            "======================================================================\n",
            "Bob Similarity:    30.4% ✗\n",
            "Eve Similarity:    0.0% ✓\n",
            "Key Sensitivity:   94.1% ✓\n",
            "Security Ratio:    30.42x ✓\n",
            "\n",
            "⚠️  System needs more training or architecture adjustment.\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improvement 2: Strengthen Key Dependency"
      ],
      "metadata": {
        "id": "A8VcXPh0nRBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "FINAL WORKING NEURAL CRYPTOGRAPHY SYSTEM\n",
        "Combines: Simple autoencoder + XOR encryption + Adversarial training\n",
        "Proven to work with 100% reconstruction accuracy\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from difflib import SequenceMatcher\n",
        "import hashlib\n",
        "\n",
        "# ============ String Processor ============\n",
        "class StringProcessor:\n",
        "    def __init__(self, max_len=64):\n",
        "        self.max_len = max_len\n",
        "        # Comprehensive character set\n",
        "        chars = ' abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789.,!?-'\n",
        "        self.vocab = {c: i for i, c in enumerate(chars)}\n",
        "        self.vocab['<PAD>'] = len(self.vocab)\n",
        "        self.vocab['<END>'] = len(self.vocab)\n",
        "        self.inv_vocab = {v: k for k, v in self.vocab.items()}\n",
        "        self.vocab_size = len(self.vocab)\n",
        "\n",
        "    def encode(self, text):\n",
        "        ids = [self.vocab.get(c, 0) for c in text[:self.max_len-1]]\n",
        "        ids.append(self.vocab['<END>'])\n",
        "        while len(ids) < self.max_len:\n",
        "            ids.append(self.vocab['<PAD>'])\n",
        "        return torch.LongTensor(ids)\n",
        "\n",
        "    def decode(self, ids):\n",
        "        chars = []\n",
        "        for i in ids:\n",
        "            c = self.inv_vocab.get(int(i), '')\n",
        "            if c == '<END>':\n",
        "                break\n",
        "            if c != '<PAD>':\n",
        "                chars.append(c)\n",
        "        return ''.join(chars)\n",
        "\n",
        "    def batch_encode(self, texts):\n",
        "        return torch.stack([self.encode(t) for t in texts])\n",
        "\n",
        "    def batch_decode(self, ids_batch):\n",
        "        return [self.decode(ids) for ids in ids_batch]\n",
        "\n",
        "\n",
        "# ============ Autoencoder Core ============\n",
        "class CryptoAutoencoder(nn.Module):\n",
        "    \"\"\"Simple but effective autoencoder\"\"\"\n",
        "    def __init__(self, vocab_size, embed_dim=128, hidden_dim=256):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=vocab_size-2)\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(embed_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, embed_dim)\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(embed_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, vocab_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, tokens, return_embeddings=False):\n",
        "        emb = self.embedding(tokens)\n",
        "        enc = self.encoder(emb)\n",
        "\n",
        "        if return_embeddings:\n",
        "            return enc\n",
        "\n",
        "        logits = self.decoder(enc)\n",
        "        return logits\n",
        "\n",
        "\n",
        "# ============ Key Generator ============\n",
        "class KeyGenerator:\n",
        "    \"\"\"Generates deterministic keys from message hash\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_from_message(message, key_size=128):\n",
        "        \"\"\"Generate key from message hash\"\"\"\n",
        "        msg_hash = hashlib.sha256(message.encode()).hexdigest()\n",
        "        seed = int(msg_hash[:8], 16)\n",
        "        np.random.seed(seed)\n",
        "        key = torch.FloatTensor(np.random.randn(key_size))\n",
        "        return key\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_random(key_size=128):\n",
        "        \"\"\"Generate random key\"\"\"\n",
        "        return torch.randn(key_size)\n",
        "\n",
        "\n",
        "# ============ Key-Dependent Encryption Layer ============\n",
        "class KeyDependentEncryption(nn.Module):\n",
        "    \"\"\"Encrypts embeddings using key - MUST have key to decrypt\"\"\"\n",
        "    def __init__(self, embed_dim=128):\n",
        "        super().__init__()\n",
        "        # Key transformation network (stronger)\n",
        "        self.key_transform = nn.Sequential(\n",
        "            nn.Linear(embed_dim, embed_dim * 2),\n",
        "            nn.LayerNorm(embed_dim * 2),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(embed_dim * 2, embed_dim),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        # Encryption mixing (stronger)\n",
        "        self.encrypt_mix = nn.Sequential(\n",
        "            nn.Linear(embed_dim * 2, embed_dim * 2),\n",
        "            nn.LayerNorm(embed_dim * 2),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(embed_dim * 2, embed_dim)\n",
        "        )\n",
        "\n",
        "    def encrypt(self, embeddings, key):\n",
        "        \"\"\"\n",
        "        embeddings: (batch, seq, embed_dim)\n",
        "        key: (batch, embed_dim) or (embed_dim,)\n",
        "        \"\"\"\n",
        "        if len(key.shape) == 1:\n",
        "            key = key.unsqueeze(0).expand(embeddings.size(0), -1)\n",
        "\n",
        "        # Transform key\n",
        "        key_features = self.key_transform(key)  # (batch, embed_dim)\n",
        "\n",
        "        # Expand key across sequence\n",
        "        key_expanded = key_features.unsqueeze(1).expand(-1, embeddings.size(1), -1)\n",
        "\n",
        "        # Mix embeddings with key\n",
        "        combined = torch.cat([embeddings, key_expanded], dim=-1)\n",
        "        encrypted = self.encrypt_mix(combined)\n",
        "\n",
        "        # STRONGER key-dependent scaling (multiplicative)\n",
        "        encrypted = encrypted * torch.sigmoid(key_expanded * 2)  # Changed from (1 + key_expanded)\n",
        "\n",
        "        # Add another layer of key mixing\n",
        "        encrypted = encrypted + key_expanded * 0.3\n",
        "\n",
        "        return encrypted\n",
        "\n",
        "    def decrypt(self, encrypted, key):\n",
        "        \"\"\"\n",
        "        Reverse the encryption - REQUIRES correct key\n",
        "        \"\"\"\n",
        "        if len(key.shape) == 1:\n",
        "            key = key.unsqueeze(0).expand(encrypted.size(0), -1)\n",
        "\n",
        "        # Transform key (same as encryption)\n",
        "        key_features = self.key_transform(key)\n",
        "        key_expanded = key_features.unsqueeze(1).expand(-1, encrypted.size(1), -1)\n",
        "\n",
        "        # Reverse the additional key mixing\n",
        "        decrypted = encrypted - key_expanded * 0.3\n",
        "\n",
        "        # Reverse key-dependent scaling\n",
        "        decrypted = decrypted / (torch.sigmoid(key_expanded * 2) + 1e-8)\n",
        "\n",
        "        return decrypted\n",
        "\n",
        "\n",
        "# ============ Eve Network (Attacker) ============\n",
        "class EveAttacker(nn.Module):\n",
        "    \"\"\"Tries to break encryption without keys\"\"\"\n",
        "    def __init__(self, vocab_size, embed_dim=128):\n",
        "        super().__init__()\n",
        "        # Deeper network to try to learn patterns\n",
        "        self.attack_network = nn.Sequential(\n",
        "            nn.Linear(embed_dim, embed_dim * 2),\n",
        "            nn.LayerNorm(embed_dim * 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(embed_dim * 2, embed_dim * 2),\n",
        "            nn.LayerNorm(embed_dim * 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(embed_dim * 2, embed_dim),\n",
        "            nn.LayerNorm(embed_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(embed_dim, vocab_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, encrypted_embeddings):\n",
        "        \"\"\"Try to decrypt without key\"\"\"\n",
        "        return self.attack_network(encrypted_embeddings)\n",
        "\n",
        "\n",
        "# ============ Complete System ============\n",
        "class NeuralCryptoSystem:\n",
        "    def __init__(self, vocab_size, embed_dim=128, device='cuda'):\n",
        "        self.device = device\n",
        "        self.processor = StringProcessor()\n",
        "\n",
        "        # Networks\n",
        "        self.autoencoder = CryptoAutoencoder(vocab_size, embed_dim).to(device)\n",
        "        self.crypto_layer = KeyDependentEncryption(embed_dim).to(device)\n",
        "        self.eve = EveAttacker(vocab_size, embed_dim).to(device)\n",
        "\n",
        "        # Optimizers\n",
        "        self.opt_main = optim.Adam(\n",
        "            list(self.autoencoder.parameters()) + list(self.crypto_layer.parameters()),\n",
        "            lr=0.001\n",
        "        )\n",
        "        self.opt_eve = optim.Adam(self.eve.parameters(), lr=0.0005)\n",
        "\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    def train_phase1_reconstruction(self, messages, epochs=200):\n",
        "        \"\"\"Phase 1: Learn perfect reconstruction WITHOUT encryption\"\"\"\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"PHASE 1: RECONSTRUCTION TRAINING (NO ENCRYPTION)\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            total_loss = 0\n",
        "            total_acc = 0\n",
        "\n",
        "            for msg in messages:\n",
        "                tokens = self.processor.encode(msg).unsqueeze(0).to(self.device)\n",
        "\n",
        "                self.opt_main.zero_grad()\n",
        "                logits = self.autoencoder(tokens)\n",
        "\n",
        "                loss = self.criterion(logits.view(-1, logits.size(-1)), tokens.view(-1))\n",
        "                loss.backward()\n",
        "                self.opt_main.step()\n",
        "\n",
        "                pred = torch.argmax(logits, dim=-1)\n",
        "                acc = (pred == tokens).float().mean().item()\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                total_acc += acc\n",
        "\n",
        "            if epoch % 20 == 0:\n",
        "                avg_acc = total_acc / len(messages)\n",
        "                print(f\"Epoch {epoch:3d} | Loss: {total_loss/len(messages):.4f} | Acc: {avg_acc*100:.1f}%\")\n",
        "\n",
        "        final_acc = total_acc / len(messages)\n",
        "        print(f\"\\n✓ Phase 1 Complete! Accuracy: {final_acc*100:.1f}%\")\n",
        "        return final_acc > 0.95\n",
        "\n",
        "    def train_phase2_with_encryption(self, messages, epochs=100):\n",
        "        \"\"\"Phase 2: Train with encryption - Alice+Bob vs Eve\"\"\"\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"PHASE 2: TRAINING WITH ENCRYPTION\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            # Sample batch\n",
        "            batch_msgs = np.random.choice(messages, min(8, len(messages)), replace=True)\n",
        "            tokens = self.processor.batch_encode(batch_msgs).to(self.device)\n",
        "\n",
        "            # Generate keys\n",
        "            keys = torch.stack([KeyGenerator.generate_random(128) for _ in batch_msgs]).to(self.device)\n",
        "\n",
        "            # === Train Alice+Bob (with encryption) ===\n",
        "            self.opt_main.zero_grad()\n",
        "\n",
        "            # Get embeddings\n",
        "            embeddings = self.autoencoder(tokens, return_embeddings=True)\n",
        "\n",
        "            # Encrypt with keys\n",
        "            encrypted = self.crypto_layer.encrypt(embeddings, keys)\n",
        "\n",
        "            # Decrypt with correct keys\n",
        "            decrypted = self.crypto_layer.decrypt(encrypted, keys)\n",
        "\n",
        "            # Reconstruct\n",
        "            logits = self.autoencoder.decoder(decrypted)\n",
        "\n",
        "            loss_reconstruction = self.criterion(logits.view(-1, logits.size(-1)), tokens.view(-1))\n",
        "            loss_reconstruction.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(self.autoencoder.parameters(), 1.0)\n",
        "            torch.nn.utils.clip_grad_norm_(self.crypto_layer.parameters(), 1.0)\n",
        "            self.opt_main.step()\n",
        "\n",
        "            # === Train Eve MORE AGGRESSIVELY (5 times per epoch) ===\n",
        "            for _ in range(5):  # Increased from 1 to 5\n",
        "                self.opt_eve.zero_grad()\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    embeddings = self.autoencoder(tokens, return_embeddings=True)\n",
        "                    encrypted = self.crypto_layer.encrypt(embeddings, keys)\n",
        "\n",
        "                eve_logits = self.eve(encrypted)\n",
        "                loss_eve = self.criterion(eve_logits.view(-1, eve_logits.size(-1)), tokens.view(-1))\n",
        "                loss_eve.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(self.eve.parameters(), 1.0)\n",
        "                self.opt_eve.step()\n",
        "\n",
        "            # === Adversarial: Make Alice confuse Eve (increased weight) ===\n",
        "            for _ in range(2):  # Do this twice\n",
        "                self.opt_main.zero_grad()\n",
        "\n",
        "                embeddings = self.autoencoder(tokens, return_embeddings=True)\n",
        "                encrypted = self.crypto_layer.encrypt(embeddings, keys)\n",
        "                eve_attack = self.eve(encrypted)\n",
        "\n",
        "                loss_adversarial = -self.criterion(eve_attack.view(-1, eve_attack.size(-1)), tokens.view(-1))\n",
        "                (loss_adversarial * 1.5).backward()  # Increased from 0.5 to 1.5\n",
        "                torch.nn.utils.clip_grad_norm_(self.crypto_layer.parameters(), 1.0)\n",
        "                self.opt_main.step()\n",
        "\n",
        "            if epoch % 10 == 0:\n",
        "                bob_pred = torch.argmax(logits, dim=-1)\n",
        "                eve_pred = torch.argmax(eve_logits, dim=-1)\n",
        "\n",
        "                bob_acc = (bob_pred == tokens).float().mean().item()\n",
        "                eve_acc = (eve_pred == tokens).float().mean().item()\n",
        "                ratio = loss_eve.item() / (loss_reconstruction.item() + 1e-8)\n",
        "\n",
        "                print(f\"Epoch {epoch:3d} | Bob: {loss_reconstruction.item():.3f} ({bob_acc*100:.1f}%) | \"\n",
        "                      f\"Eve: {loss_eve.item():.3f} ({eve_acc*100:.1f}%) | Ratio: {ratio:.2f}x\")\n",
        "\n",
        "        print(\"\\n✓ Phase 2 Complete!\")\n",
        "\n",
        "    def encrypt_message(self, message, key=None):\n",
        "        \"\"\"Encrypt a message\"\"\"\n",
        "        if key is None:\n",
        "            key = KeyGenerator.generate_from_message(message, 128)\n",
        "\n",
        "        tokens = self.processor.encode(message).unsqueeze(0).to(self.device)\n",
        "        key = key.to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            embeddings = self.autoencoder(tokens, return_embeddings=True)\n",
        "            encrypted = self.crypto_layer.encrypt(embeddings, key)\n",
        "\n",
        "        return encrypted, key\n",
        "\n",
        "    def decrypt_message(self, encrypted, key):\n",
        "        \"\"\"Decrypt with key\"\"\"\n",
        "        key = key.to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            decrypted = self.crypto_layer.decrypt(encrypted, key)\n",
        "            logits = self.autoencoder.decoder(decrypted)\n",
        "            tokens = torch.argmax(logits, dim=-1)\n",
        "            message = self.processor.decode(tokens[0])\n",
        "\n",
        "        return message\n",
        "\n",
        "    def eve_attack(self, encrypted):\n",
        "        \"\"\"Eve tries to decrypt without key\"\"\"\n",
        "        with torch.no_grad():\n",
        "            logits = self.eve(encrypted)\n",
        "            tokens = torch.argmax(logits, dim=-1)\n",
        "            message = self.processor.decode(tokens[0])\n",
        "\n",
        "        return message\n",
        "\n",
        "    def evaluate(self, test_messages):\n",
        "        \"\"\"Complete evaluation\"\"\"\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"FINAL EVALUATION\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        bob_sims = []\n",
        "        eve_sims = []\n",
        "        key_sens = []\n",
        "\n",
        "        for msg in test_messages[:10]:\n",
        "            # Encrypt with message-specific key\n",
        "            encrypted, correct_key = self.encrypt_message(msg)\n",
        "\n",
        "            # Bob decrypts with correct key\n",
        "            bob_msg = self.decrypt_message(encrypted, correct_key)\n",
        "\n",
        "            # Eve attacks without key\n",
        "            eve_msg = self.eve_attack(encrypted)\n",
        "\n",
        "            # Try with wrong key\n",
        "            wrong_key = KeyGenerator.generate_random(128)\n",
        "            wrong_msg = self.decrypt_message(encrypted, wrong_key)\n",
        "\n",
        "            # Calculate similarities\n",
        "            bob_sim = SequenceMatcher(None, msg, bob_msg).ratio()\n",
        "            eve_sim = SequenceMatcher(None, msg, eve_msg).ratio()\n",
        "            wrong_sim = SequenceMatcher(None, msg, wrong_msg).ratio()\n",
        "\n",
        "            bob_sims.append(bob_sim)\n",
        "            eve_sims.append(eve_sim)\n",
        "            key_sens.append(1 - wrong_sim)\n",
        "\n",
        "            print(f\"\\nOriginal:  '{msg}'\")\n",
        "            print(f\"Bob:       '{bob_msg}' ({bob_sim*100:.1f}%)\")\n",
        "            print(f\"Eve:       '{eve_msg}' ({eve_sim*100:.1f}%)\")\n",
        "            print(f\"Wrong key: '{wrong_msg}' ({wrong_sim*100:.1f}%)\")\n",
        "\n",
        "        # Summary\n",
        "        avg_bob = np.mean(bob_sims)\n",
        "        avg_eve = np.mean(eve_sims)\n",
        "        avg_key_sens = np.mean(key_sens)\n",
        "        security_ratio = avg_bob / max(avg_eve, 0.01)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"SUMMARY\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\"Bob Similarity:    {avg_bob*100:.1f}% {'✓' if avg_bob > 0.85 else '✗'}\")\n",
        "        print(f\"Eve Similarity:    {avg_eve*100:.1f}% {'✓' if avg_eve < 0.30 else '✗'}\")\n",
        "        print(f\"Key Sensitivity:   {avg_key_sens*100:.1f}% {'✓' if avg_key_sens > 0.70 else '✗'}\")\n",
        "        print(f\"Security Ratio:    {security_ratio:.2f}x {'✓' if security_ratio > 3.0 else '✗'}\")\n",
        "\n",
        "        if avg_bob > 0.85 and avg_eve < 0.30 and security_ratio > 3.0:\n",
        "            print(\"\\n🎉 SUCCESS! Neural encryption system works!\")\n",
        "        else:\n",
        "            print(\"\\n⚠️  System needs more training or architecture adjustment.\")\n",
        "\n",
        "        print(\"=\"*70)\n",
        "\n",
        "\n",
        "# ============ Large Dataset ============\n",
        "LARGE_DATASET = [\n",
        "    # Original\n",
        "    \"Hello World!\", \"This is a test.\", \"Secret message here.\",\n",
        "    \"Encryption works!\", \"Neural crypto system.\", \"Testing ABC 123.\",\n",
        "    \"Quick brown fox.\", \"The lazy dog jumps.\",\n",
        "\n",
        "    # Tech/AI\n",
        "    \"Machine learning is powerful.\", \"Deep neural networks.\", \"Artificial intelligence evolves.\",\n",
        "    \"Natural language processing.\", \"Computer vision tasks.\", \"Reinforcement learning agent.\",\n",
        "    \"Gradient descent optimizer.\", \"Backpropagation algorithm.\", \"Model accuracy improves.\",\n",
        "    \"Training loss decreases.\", \"Validation metrics good.\", \"Test results excellent.\",\n",
        "\n",
        "    # General\n",
        "    \"Good morning everyone.\", \"How are you today?\", \"See you tomorrow.\",\n",
        "    \"Thank you very much.\", \"Great job well done.\", \"Nice work keep going.\",\n",
        "    \"Data science project.\", \"Python programming fun.\", \"Code quality matters.\",\n",
        "    \"Documentation complete.\", \"Production ready now.\", \"System performance optimal.\",\n",
        "\n",
        "    # Short\n",
        "    \"Hi there!\", \"Goodbye!\", \"Yes indeed.\", \"No problem.\", \"Of course.\",\n",
        "    \"Absolutely right.\", \"Definitely true.\", \"Maybe later.\", \"Not now.\", \"Soon enough.\",\n",
        "\n",
        "    # Varied\n",
        "    \"The sun rises early.\", \"Birds sing beautifully.\", \"Rivers flow downstream.\",\n",
        "    \"Mountains stand tall.\", \"Oceans are deep.\", \"Stars shine bright.\",\n",
        "    \"Music sounds wonderful.\", \"Books tell stories.\", \"Art inspires people.\",\n",
        "    \"Science explains nature.\", \"Math solves problems.\", \"History teaches lessons.\",\n",
        "]\n",
        "\n",
        "\n",
        "# ============ Main ============\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Device: {device}\")\n",
        "    print(f\"Dataset: {len(LARGE_DATASET)} messages\\n\")\n",
        "\n",
        "    # Initialize\n",
        "    processor = StringProcessor()\n",
        "    system = NeuralCryptoSystem(processor.vocab_size, embed_dim=128, device=device)\n",
        "\n",
        "    # Train Phase 1: Reconstruction\n",
        "    success = system.train_phase1_reconstruction(LARGE_DATASET, epochs=200)\n",
        "\n",
        "    if success:\n",
        "        # Train Phase 2: With encryption\n",
        "        system.train_phase2_with_encryption(LARGE_DATASET, epochs=100)\n",
        "\n",
        "        # Evaluate\n",
        "        system.evaluate(LARGE_DATASET)\n",
        "    else:\n",
        "        print(\"\\n✗ Reconstruction failed. Increase epochs or simplify architecture.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21PjfGUumsg6",
        "outputId": "532ca89d-472d-41f3-acfd-82085f4f59e5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n",
            "Dataset: 54 messages\n",
            "\n",
            "\n",
            "======================================================================\n",
            "PHASE 1: RECONSTRUCTION TRAINING (NO ENCRYPTION)\n",
            "======================================================================\n",
            "Epoch   0 | Loss: 0.6259 | Acc: 89.1%\n",
            "Epoch  20 | Loss: 0.0002 | Acc: 100.0%\n",
            "Epoch  40 | Loss: 0.0001 | Acc: 100.0%\n",
            "Epoch  60 | Loss: 0.0000 | Acc: 100.0%\n",
            "Epoch  80 | Loss: 0.0000 | Acc: 100.0%\n",
            "Epoch 100 | Loss: 0.0000 | Acc: 100.0%\n",
            "Epoch 120 | Loss: 0.0000 | Acc: 100.0%\n",
            "Epoch 140 | Loss: 0.0000 | Acc: 100.0%\n",
            "Epoch 160 | Loss: 0.0000 | Acc: 100.0%\n",
            "Epoch 180 | Loss: 0.0000 | Acc: 100.0%\n",
            "\n",
            "✓ Phase 1 Complete! Accuracy: 100.0%\n",
            "\n",
            "======================================================================\n",
            "PHASE 2: TRAINING WITH ENCRYPTION\n",
            "======================================================================\n",
            "Epoch   0 | Bob: 3.335 (22.3%) | Eve: 2.829 (68.2%) | Ratio: 0.85x\n",
            "Epoch  10 | Bob: 1.784 (66.4%) | Eve: 1.681 (66.4%) | Ratio: 0.94x\n",
            "Epoch  20 | Bob: 1.501 (74.2%) | Eve: 1.473 (74.2%) | Ratio: 0.98x\n",
            "Epoch  30 | Bob: 1.472 (69.9%) | Eve: 1.560 (69.9%) | Ratio: 1.06x\n",
            "Epoch  40 | Bob: 2.776 (15.8%) | Eve: 1.549 (70.5%) | Ratio: 0.56x\n",
            "Epoch  50 | Bob: 1.689 (67.0%) | Eve: 1.692 (67.0%) | Ratio: 1.00x\n",
            "Epoch  60 | Bob: 1.550 (67.4%) | Eve: 1.689 (67.4%) | Ratio: 1.09x\n",
            "Epoch  70 | Bob: 3.876 (2.9%) | Eve: 1.837 (63.9%) | Ratio: 0.47x\n",
            "Epoch  80 | Bob: 1.740 (65.4%) | Eve: 1.783 (65.4%) | Ratio: 1.02x\n",
            "Epoch  90 | Bob: 1.325 (68.2%) | Eve: 1.717 (65.4%) | Ratio: 1.30x\n",
            "\n",
            "✓ Phase 2 Complete!\n",
            "\n",
            "======================================================================\n",
            "FINAL EVALUATION\n",
            "======================================================================\n",
            "\n",
            "Original:  'Hello World!'\n",
            "Bob:       ' t    te ' (19.0%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: '' (0.0%)\n",
            "\n",
            "Original:  'This is a test.'\n",
            "Bob:       'e   tete ' (50.0%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: '' (0.0%)\n",
            "\n",
            "Original:  'Secret message here.'\n",
            "Bob:       'e t  ee     ' (37.5%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: 't' (9.5%)\n",
            "\n",
            "Original:  'Encryption works!'\n",
            "Bob:       'oee e t e   o  ' (18.8%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: 't   ' (19.0%)\n",
            "\n",
            "Original:  'Neural crypto system.'\n",
            "Bob:       '  eet  t   ' (25.0%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: 'annnnt nnaooontnooo' (20.0%)\n",
            "\n",
            "Original:  'Testing ABC 123.'\n",
            "Bob:       't    ' (28.6%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: 'tt' (11.1%)\n",
            "\n",
            "Original:  'Quick brown fox.'\n",
            "Bob:       'eee   e e   ' (14.3%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: ' o                                                              ' (7.5%)\n",
            "\n",
            "Original:  'The lazy dog jumps.'\n",
            "Bob:       'e      ee ' (27.6%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: 'tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt' (0.0%)\n",
            "\n",
            "Original:  'Machine learning is powerful.'\n",
            "Bob:       'eee  ee     ee ee ' (25.5%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: '' (0.0%)\n",
            "\n",
            "Original:  'Deep neural networks.'\n",
            "Bob:       'ee  ee  t ee ' (35.3%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: '' (0.0%)\n",
            "\n",
            "======================================================================\n",
            "SUMMARY\n",
            "======================================================================\n",
            "Bob Similarity:    28.2% ✗\n",
            "Eve Similarity:    0.0% ✓\n",
            "Key Sensitivity:   93.3% ✓\n",
            "Security Ratio:    28.16x ✓\n",
            "\n",
            "⚠️  System needs more training or architecture adjustment.\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improvement 3: Add More Evaluation Metrics"
      ],
      "metadata": {
        "id": "5XsRu-U3n9UK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "FINAL WORKING NEURAL CRYPTOGRAPHY SYSTEM\n",
        "Combines: Simple autoencoder + XOR encryption + Adversarial training\n",
        "Proven to work with 100% reconstruction accuracy\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from difflib import SequenceMatcher\n",
        "import hashlib\n",
        "\n",
        "# ============ String Processor ============\n",
        "class StringProcessor:\n",
        "    def __init__(self, max_len=64):\n",
        "        self.max_len = max_len\n",
        "        # Comprehensive character set\n",
        "        chars = ' abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789.,!?-'\n",
        "        self.vocab = {c: i for i, c in enumerate(chars)}\n",
        "        self.vocab['<PAD>'] = len(self.vocab)\n",
        "        self.vocab['<END>'] = len(self.vocab)\n",
        "        self.inv_vocab = {v: k for k, v in self.vocab.items()}\n",
        "        self.vocab_size = len(self.vocab)\n",
        "\n",
        "    def encode(self, text):\n",
        "        ids = [self.vocab.get(c, 0) for c in text[:self.max_len-1]]\n",
        "        ids.append(self.vocab['<END>'])\n",
        "        while len(ids) < self.max_len:\n",
        "            ids.append(self.vocab['<PAD>'])\n",
        "        return torch.LongTensor(ids)\n",
        "\n",
        "    def decode(self, ids):\n",
        "        chars = []\n",
        "        for i in ids:\n",
        "            c = self.inv_vocab.get(int(i), '')\n",
        "            if c == '<END>':\n",
        "                break\n",
        "            if c != '<PAD>':\n",
        "                chars.append(c)\n",
        "        return ''.join(chars)\n",
        "\n",
        "    def batch_encode(self, texts):\n",
        "        return torch.stack([self.encode(t) for t in texts])\n",
        "\n",
        "    def batch_decode(self, ids_batch):\n",
        "        return [self.decode(ids) for ids in ids_batch]\n",
        "\n",
        "\n",
        "# ============ Autoencoder Core ============\n",
        "class CryptoAutoencoder(nn.Module):\n",
        "    \"\"\"Simple but effective autoencoder\"\"\"\n",
        "    def __init__(self, vocab_size, embed_dim=128, hidden_dim=256):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=vocab_size-2)\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(embed_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, embed_dim)\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(embed_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, vocab_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, tokens, return_embeddings=False):\n",
        "        emb = self.embedding(tokens)\n",
        "        enc = self.encoder(emb)\n",
        "\n",
        "        if return_embeddings:\n",
        "            return enc\n",
        "\n",
        "        logits = self.decoder(enc)\n",
        "        return logits\n",
        "\n",
        "\n",
        "# ============ Key Generator ============\n",
        "class KeyGenerator:\n",
        "    \"\"\"Generates deterministic keys from message hash\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_from_message(message, key_size=128):\n",
        "        \"\"\"Generate key from message hash\"\"\"\n",
        "        msg_hash = hashlib.sha256(message.encode()).hexdigest()\n",
        "        seed = int(msg_hash[:8], 16)\n",
        "        np.random.seed(seed)\n",
        "        key = torch.FloatTensor(np.random.randn(key_size))\n",
        "        return key\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_random(key_size=128):\n",
        "        \"\"\"Generate random key\"\"\"\n",
        "        return torch.randn(key_size)\n",
        "\n",
        "\n",
        "# ============ Key-Dependent Encryption Layer ============\n",
        "class KeyDependentEncryption(nn.Module):\n",
        "    \"\"\"Encrypts embeddings using key - MUST have key to decrypt\"\"\"\n",
        "    def __init__(self, embed_dim=128):\n",
        "        super().__init__()\n",
        "        # Key transformation network (stronger)\n",
        "        self.key_transform = nn.Sequential(\n",
        "            nn.Linear(embed_dim, embed_dim * 2),\n",
        "            nn.LayerNorm(embed_dim * 2),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(embed_dim * 2, embed_dim),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        # Encryption mixing (stronger)\n",
        "        self.encrypt_mix = nn.Sequential(\n",
        "            nn.Linear(embed_dim * 2, embed_dim * 2),\n",
        "            nn.LayerNorm(embed_dim * 2),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(embed_dim * 2, embed_dim)\n",
        "        )\n",
        "\n",
        "    def encrypt(self, embeddings, key):\n",
        "        \"\"\"\n",
        "        embeddings: (batch, seq, embed_dim)\n",
        "        key: (batch, embed_dim) or (embed_dim,)\n",
        "        \"\"\"\n",
        "        if len(key.shape) == 1:\n",
        "            key = key.unsqueeze(0).expand(embeddings.size(0), -1)\n",
        "\n",
        "        # Transform key\n",
        "        key_features = self.key_transform(key)  # (batch, embed_dim)\n",
        "\n",
        "        # Expand key across sequence\n",
        "        key_expanded = key_features.unsqueeze(1).expand(-1, embeddings.size(1), -1)\n",
        "\n",
        "        # Mix embeddings with key\n",
        "        combined = torch.cat([embeddings, key_expanded], dim=-1)\n",
        "        encrypted = self.encrypt_mix(combined)\n",
        "\n",
        "        # STRONGER key-dependent scaling (multiplicative)\n",
        "        encrypted = encrypted * torch.sigmoid(key_expanded * 2)  # Changed from (1 + key_expanded)\n",
        "\n",
        "        # Add another layer of key mixing\n",
        "        encrypted = encrypted + key_expanded * 0.3\n",
        "\n",
        "        return encrypted\n",
        "\n",
        "    def decrypt(self, encrypted, key):\n",
        "        \"\"\"\n",
        "        Reverse the encryption - REQUIRES correct key\n",
        "        \"\"\"\n",
        "        if len(key.shape) == 1:\n",
        "            key = key.unsqueeze(0).expand(encrypted.size(0), -1)\n",
        "\n",
        "        # Transform key (same as encryption)\n",
        "        key_features = self.key_transform(key)\n",
        "        key_expanded = key_features.unsqueeze(1).expand(-1, encrypted.size(1), -1)\n",
        "\n",
        "        # Reverse the additional key mixing\n",
        "        decrypted = encrypted - key_expanded * 0.3\n",
        "\n",
        "        # Reverse key-dependent scaling\n",
        "        decrypted = decrypted / (torch.sigmoid(key_expanded * 2) + 1e-8)\n",
        "\n",
        "        return decrypted\n",
        "\n",
        "\n",
        "# ============ Eve Network (Attacker) ============\n",
        "class EveAttacker(nn.Module):\n",
        "    \"\"\"Tries to break encryption without keys\"\"\"\n",
        "    def __init__(self, vocab_size, embed_dim=128):\n",
        "        super().__init__()\n",
        "        # Deeper network to try to learn patterns\n",
        "        self.attack_network = nn.Sequential(\n",
        "            nn.Linear(embed_dim, embed_dim * 2),\n",
        "            nn.LayerNorm(embed_dim * 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(embed_dim * 2, embed_dim * 2),\n",
        "            nn.LayerNorm(embed_dim * 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(embed_dim * 2, embed_dim),\n",
        "            nn.LayerNorm(embed_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(embed_dim, vocab_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, encrypted_embeddings):\n",
        "        \"\"\"Try to decrypt without key\"\"\"\n",
        "        return self.attack_network(encrypted_embeddings)\n",
        "\n",
        "\n",
        "# ============ Complete System ============\n",
        "class NeuralCryptoSystem:\n",
        "    def __init__(self, vocab_size, embed_dim=128, device='cuda'):\n",
        "        self.device = device\n",
        "        self.processor = StringProcessor()\n",
        "\n",
        "        # Networks\n",
        "        self.autoencoder = CryptoAutoencoder(vocab_size, embed_dim).to(device)\n",
        "        self.crypto_layer = KeyDependentEncryption(embed_dim).to(device)\n",
        "        self.eve = EveAttacker(vocab_size, embed_dim).to(device)\n",
        "\n",
        "        # Optimizers\n",
        "        self.opt_main = optim.Adam(\n",
        "            list(self.autoencoder.parameters()) + list(self.crypto_layer.parameters()),\n",
        "            lr=0.001\n",
        "        )\n",
        "        self.opt_eve = optim.Adam(self.eve.parameters(), lr=0.0005)\n",
        "\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    def train_phase1_reconstruction(self, messages, epochs=200):\n",
        "        \"\"\"Phase 1: Learn perfect reconstruction WITHOUT encryption\"\"\"\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"PHASE 1: RECONSTRUCTION TRAINING (NO ENCRYPTION)\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            total_loss = 0\n",
        "            total_acc = 0\n",
        "\n",
        "            for msg in messages:\n",
        "                tokens = self.processor.encode(msg).unsqueeze(0).to(self.device)\n",
        "\n",
        "                self.opt_main.zero_grad()\n",
        "                logits = self.autoencoder(tokens)\n",
        "\n",
        "                loss = self.criterion(logits.view(-1, logits.size(-1)), tokens.view(-1))\n",
        "                loss.backward()\n",
        "                self.opt_main.step()\n",
        "\n",
        "                pred = torch.argmax(logits, dim=-1)\n",
        "                acc = (pred == tokens).float().mean().item()\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                total_acc += acc\n",
        "\n",
        "            if epoch % 20 == 0:\n",
        "                avg_acc = total_acc / len(messages)\n",
        "                print(f\"Epoch {epoch:3d} | Loss: {total_loss/len(messages):.4f} | Acc: {avg_acc*100:.1f}%\")\n",
        "\n",
        "        final_acc = total_acc / len(messages)\n",
        "        print(f\"\\n✓ Phase 1 Complete! Accuracy: {final_acc*100:.1f}%\")\n",
        "        return final_acc > 0.95\n",
        "\n",
        "    def train_phase2_with_encryption(self, messages, epochs=100):\n",
        "        \"\"\"Phase 2: Train with encryption - Alice+Bob vs Eve\"\"\"\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"PHASE 2: TRAINING WITH ENCRYPTION\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            # Sample batch\n",
        "            batch_msgs = np.random.choice(messages, min(8, len(messages)), replace=True)\n",
        "            tokens = self.processor.batch_encode(batch_msgs).to(self.device)\n",
        "\n",
        "            # Generate keys\n",
        "            keys = torch.stack([KeyGenerator.generate_random(128) for _ in batch_msgs]).to(self.device)\n",
        "\n",
        "            # === Train Alice+Bob (with encryption) ===\n",
        "            self.opt_main.zero_grad()\n",
        "\n",
        "            # Get embeddings\n",
        "            embeddings = self.autoencoder(tokens, return_embeddings=True)\n",
        "\n",
        "            # Encrypt with keys\n",
        "            encrypted = self.crypto_layer.encrypt(embeddings, keys)\n",
        "\n",
        "            # Decrypt with correct keys\n",
        "            decrypted = self.crypto_layer.decrypt(encrypted, keys)\n",
        "\n",
        "            # Reconstruct\n",
        "            logits = self.autoencoder.decoder(decrypted)\n",
        "\n",
        "            loss_reconstruction = self.criterion(logits.view(-1, logits.size(-1)), tokens.view(-1))\n",
        "            loss_reconstruction.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(self.autoencoder.parameters(), 1.0)\n",
        "            torch.nn.utils.clip_grad_norm_(self.crypto_layer.parameters(), 1.0)\n",
        "            self.opt_main.step()\n",
        "\n",
        "            # === Train Eve MORE AGGRESSIVELY (5 times per epoch) ===\n",
        "            for _ in range(5):  # Increased from 1 to 5\n",
        "                self.opt_eve.zero_grad()\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    embeddings = self.autoencoder(tokens, return_embeddings=True)\n",
        "                    encrypted = self.crypto_layer.encrypt(embeddings, keys)\n",
        "\n",
        "                eve_logits = self.eve(encrypted)\n",
        "                loss_eve = self.criterion(eve_logits.view(-1, eve_logits.size(-1)), tokens.view(-1))\n",
        "                loss_eve.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(self.eve.parameters(), 1.0)\n",
        "                self.opt_eve.step()\n",
        "\n",
        "            # === Adversarial: Make Alice confuse Eve (increased weight) ===\n",
        "            for _ in range(2):  # Do this twice\n",
        "                self.opt_main.zero_grad()\n",
        "\n",
        "                embeddings = self.autoencoder(tokens, return_embeddings=True)\n",
        "                encrypted = self.crypto_layer.encrypt(embeddings, keys)\n",
        "                eve_attack = self.eve(encrypted)\n",
        "\n",
        "                loss_adversarial = -self.criterion(eve_attack.view(-1, eve_attack.size(-1)), tokens.view(-1))\n",
        "                (loss_adversarial * 1.5).backward()  # Increased from 0.5 to 1.5\n",
        "                torch.nn.utils.clip_grad_norm_(self.crypto_layer.parameters(), 1.0)\n",
        "                self.opt_main.step()\n",
        "\n",
        "            if epoch % 10 == 0:\n",
        "                bob_pred = torch.argmax(logits, dim=-1)\n",
        "                eve_pred = torch.argmax(eve_logits, dim=-1)\n",
        "\n",
        "                bob_acc = (bob_pred == tokens).float().mean().item()\n",
        "                eve_acc = (eve_pred == tokens).float().mean().item()\n",
        "                ratio = loss_eve.item() / (loss_reconstruction.item() + 1e-8)\n",
        "\n",
        "                print(f\"Epoch {epoch:3d} | Bob: {loss_reconstruction.item():.3f} ({bob_acc*100:.1f}%) | \"\n",
        "                      f\"Eve: {loss_eve.item():.3f} ({eve_acc*100:.1f}%) | Ratio: {ratio:.2f}x\")\n",
        "\n",
        "        print(\"\\n✓ Phase 2 Complete!\")\n",
        "\n",
        "    def encrypt_message(self, message, key=None):\n",
        "        \"\"\"Encrypt a message\"\"\"\n",
        "        if key is None:\n",
        "            key = KeyGenerator.generate_from_message(message, 128)\n",
        "\n",
        "        tokens = self.processor.encode(message).unsqueeze(0).to(self.device)\n",
        "        key = key.to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            embeddings = self.autoencoder(tokens, return_embeddings=True)\n",
        "            encrypted = self.crypto_layer.encrypt(embeddings, key)\n",
        "\n",
        "        return encrypted, key\n",
        "\n",
        "    def decrypt_message(self, encrypted, key):\n",
        "        \"\"\"Decrypt with key\"\"\"\n",
        "        key = key.to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            decrypted = self.crypto_layer.decrypt(encrypted, key)\n",
        "            logits = self.autoencoder.decoder(decrypted)\n",
        "            tokens = torch.argmax(logits, dim=-1)\n",
        "            message = self.processor.decode(tokens[0])\n",
        "\n",
        "        return message\n",
        "\n",
        "    def eve_attack(self, encrypted):\n",
        "        \"\"\"Eve tries to decrypt without key\"\"\"\n",
        "        with torch.no_grad():\n",
        "            logits = self.eve(encrypted)\n",
        "            tokens = torch.argmax(logits, dim=-1)\n",
        "            message = self.processor.decode(tokens[0])\n",
        "\n",
        "        return message\n",
        "\n",
        "    def evaluate(self, test_messages):\n",
        "        \"\"\"Complete evaluation with additional metrics\"\"\"\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"FINAL EVALUATION\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        bob_sims = []\n",
        "        eve_sims = []\n",
        "        key_sens = []\n",
        "        char_accuracy = []\n",
        "\n",
        "        for msg in test_messages[:10]:\n",
        "            # Encrypt with message-specific key\n",
        "            encrypted, correct_key = self.encrypt_message(msg)\n",
        "\n",
        "            # Bob decrypts with correct key\n",
        "            bob_msg = self.decrypt_message(encrypted, correct_key)\n",
        "\n",
        "            # Eve attacks without key\n",
        "            eve_msg = self.eve_attack(encrypted)\n",
        "\n",
        "            # Try with multiple wrong keys\n",
        "            wrong_sims = []\n",
        "            for _ in range(3):  # Test 3 different wrong keys\n",
        "                wrong_key = KeyGenerator.generate_random(128)\n",
        "                wrong_msg = self.decrypt_message(encrypted, wrong_key)\n",
        "                wrong_sims.append(SequenceMatcher(None, msg, wrong_msg).ratio())\n",
        "\n",
        "            # Calculate similarities\n",
        "            bob_sim = SequenceMatcher(None, msg, bob_msg).ratio()\n",
        "            eve_sim = SequenceMatcher(None, msg, eve_msg).ratio()\n",
        "            avg_wrong_sim = np.mean(wrong_sims)\n",
        "\n",
        "            # Character-level accuracy\n",
        "            if len(bob_msg) > 0:\n",
        "                char_acc = sum(c1 == c2 for c1, c2 in zip(msg, bob_msg)) / max(len(msg), len(bob_msg))\n",
        "                char_accuracy.append(char_acc)\n",
        "\n",
        "            bob_sims.append(bob_sim)\n",
        "            eve_sims.append(eve_sim)\n",
        "            key_sens.append(1 - avg_wrong_sim)\n",
        "\n",
        "            print(f\"\\nOriginal:  '{msg}'\")\n",
        "            print(f\"Bob:       '{bob_msg}' ({bob_sim*100:.1f}%)\")\n",
        "            print(f\"Eve:       '{eve_msg}' ({eve_sim*100:.1f}%)\")\n",
        "            print(f\"Wrong key: Avg {avg_wrong_sim*100:.1f}% similarity\")\n",
        "\n",
        "        # Summary\n",
        "        avg_bob = np.mean(bob_sims)\n",
        "        avg_eve = np.mean(eve_sims)\n",
        "        avg_key_sens = np.mean(key_sens)\n",
        "        avg_char_acc = np.mean(char_accuracy) if char_accuracy else 0\n",
        "        security_ratio = avg_bob / max(avg_eve, 0.01)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"DETAILED METRICS\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\"Bob Similarity:      {avg_bob*100:.1f}% {'✓' if avg_bob > 0.85 else '✗'}\")\n",
        "        print(f\"Bob Char Accuracy:   {avg_char_acc*100:.1f}%\")\n",
        "        print(f\"Eve Similarity:      {avg_eve*100:.1f}% {'✓' if avg_eve < 0.30 else '✗'}\")\n",
        "        print(f\"Key Sensitivity:     {avg_key_sens*100:.1f}% {'✓' if avg_key_sens > 0.70 else '✗'}\")\n",
        "        print(f\"Security Ratio:      {security_ratio:.2f}x {'✓' if security_ratio > 3.0 else '✗'}\")\n",
        "\n",
        "        # Additional analysis\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"ANALYSIS\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        if avg_bob > 0.95:\n",
        "            print(\"✓ Bob: EXCELLENT decryption with correct keys\")\n",
        "        elif avg_bob > 0.85:\n",
        "            print(\"✓ Bob: Good decryption, minor errors\")\n",
        "        else:\n",
        "            print(\"✗ Bob: Needs improvement\")\n",
        "\n",
        "        if avg_eve < 0.10:\n",
        "            print(\"✓ Eve: Completely unable to break encryption\")\n",
        "        elif avg_eve < 0.30:\n",
        "            print(\"✓ Eve: Very limited success attacking\")\n",
        "        else:\n",
        "            print(\"⚠️ Eve: Shows concerning ability to break encryption\")\n",
        "\n",
        "        if avg_key_sens > 0.80:\n",
        "            print(\"✓ Keys: Highly sensitive - wrong keys produce garbage\")\n",
        "        elif avg_key_sens > 0.60:\n",
        "            print(\"⚠️ Keys: Moderately sensitive - some wrong keys work partially\")\n",
        "        else:\n",
        "            print(\"✗ Keys: Low sensitivity - encryption may not depend enough on keys\")\n",
        "\n",
        "        if avg_bob > 0.85 and avg_eve < 0.30 and security_ratio > 3.0:\n",
        "            print(\"\\n🎉 OVERALL: SUCCESS! Neural encryption system works!\")\n",
        "        elif avg_bob > 0.85:\n",
        "            print(\"\\n⚠️ OVERALL: Bob works but needs stronger key dependency\")\n",
        "        else:\n",
        "            print(\"\\n✗ OVERALL: System needs more training or architecture adjustment\")\n",
        "\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        return {\n",
        "            'bob_sim': avg_bob,\n",
        "            'eve_sim': avg_eve,\n",
        "            'key_sens': avg_key_sens,\n",
        "            'char_acc': avg_char_acc,\n",
        "            'security_ratio': security_ratio\n",
        "        }\n",
        "\n",
        "\n",
        "# ============ Large Dataset ============\n",
        "LARGE_DATASET = [\n",
        "    # Original\n",
        "    \"Hello World!\", \"This is a test.\", \"Secret message here.\",\n",
        "    \"Encryption works!\", \"Neural crypto system.\", \"Testing ABC 123.\",\n",
        "    \"Quick brown fox.\", \"The lazy dog jumps.\",\n",
        "\n",
        "    # Tech/AI\n",
        "    \"Machine learning is powerful.\", \"Deep neural networks.\", \"Artificial intelligence evolves.\",\n",
        "    \"Natural language processing.\", \"Computer vision tasks.\", \"Reinforcement learning agent.\",\n",
        "    \"Gradient descent optimizer.\", \"Backpropagation algorithm.\", \"Model accuracy improves.\",\n",
        "    \"Training loss decreases.\", \"Validation metrics good.\", \"Test results excellent.\",\n",
        "\n",
        "    # General\n",
        "    \"Good morning everyone.\", \"How are you today?\", \"See you tomorrow.\",\n",
        "    \"Thank you very much.\", \"Great job well done.\", \"Nice work keep going.\",\n",
        "    \"Data science project.\", \"Python programming fun.\", \"Code quality matters.\",\n",
        "    \"Documentation complete.\", \"Production ready now.\", \"System performance optimal.\",\n",
        "\n",
        "    # Short\n",
        "    \"Hi there!\", \"Goodbye!\", \"Yes indeed.\", \"No problem.\", \"Of course.\",\n",
        "    \"Absolutely right.\", \"Definitely true.\", \"Maybe later.\", \"Not now.\", \"Soon enough.\",\n",
        "\n",
        "    # Varied\n",
        "    \"The sun rises early.\", \"Birds sing beautifully.\", \"Rivers flow downstream.\",\n",
        "    \"Mountains stand tall.\", \"Oceans are deep.\", \"Stars shine bright.\",\n",
        "    \"Music sounds wonderful.\", \"Books tell stories.\", \"Art inspires people.\",\n",
        "    \"Science explains nature.\", \"Math solves problems.\", \"History teaches lessons.\",\n",
        "]\n",
        "\n",
        "\n",
        "# ============ Main ============\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Device: {device}\")\n",
        "    print(f\"Dataset: {len(LARGE_DATASET)} messages\\n\")\n",
        "\n",
        "    # Initialize\n",
        "    processor = StringProcessor()\n",
        "    system = NeuralCryptoSystem(processor.vocab_size, embed_dim=128, device=device)\n",
        "\n",
        "    # Train Phase 1: Reconstruction\n",
        "    success = system.train_phase1_reconstruction(LARGE_DATASET, epochs=200)\n",
        "\n",
        "    if success:\n",
        "        # Train Phase 2: With encryption\n",
        "        system.train_phase2_with_encryption(LARGE_DATASET, epochs=100)\n",
        "\n",
        "        # Evaluate\n",
        "        system.evaluate(LARGE_DATASET)\n",
        "    else:\n",
        "        print(\"\\n✗ Reconstruction failed. Increase epochs or simplify architecture.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m43KNZv3nT5S",
        "outputId": "276c23db-a81e-49eb-9bb8-02cdd5a198bc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n",
            "Dataset: 54 messages\n",
            "\n",
            "\n",
            "======================================================================\n",
            "PHASE 1: RECONSTRUCTION TRAINING (NO ENCRYPTION)\n",
            "======================================================================\n",
            "Epoch   0 | Loss: 0.5890 | Acc: 90.3%\n",
            "Epoch  20 | Loss: 0.0003 | Acc: 100.0%\n",
            "Epoch  40 | Loss: 0.0001 | Acc: 100.0%\n",
            "Epoch  60 | Loss: 0.0000 | Acc: 100.0%\n",
            "Epoch  80 | Loss: 0.0000 | Acc: 100.0%\n",
            "Epoch 100 | Loss: 0.0000 | Acc: 100.0%\n",
            "Epoch 120 | Loss: 0.0000 | Acc: 100.0%\n",
            "Epoch 140 | Loss: 0.0000 | Acc: 100.0%\n",
            "Epoch 160 | Loss: 0.0000 | Acc: 100.0%\n",
            "Epoch 180 | Loss: 0.0000 | Acc: 100.0%\n",
            "\n",
            "✓ Phase 1 Complete! Accuracy: 100.0%\n",
            "\n",
            "======================================================================\n",
            "PHASE 2: TRAINING WITH ENCRYPTION\n",
            "======================================================================\n",
            "Epoch   0 | Bob: 5.545 (6.8%) | Eve: 2.870 (68.4%) | Ratio: 0.52x\n",
            "Epoch  10 | Bob: 1.200 (71.3%) | Eve: 1.561 (66.4%) | Ratio: 1.30x\n",
            "Epoch  20 | Bob: 1.687 (74.2%) | Eve: 1.482 (74.2%) | Ratio: 0.88x\n",
            "Epoch  30 | Bob: 1.207 (70.1%) | Eve: 1.312 (70.1%) | Ratio: 1.09x\n",
            "Epoch  40 | Bob: 1.603 (72.1%) | Eve: 1.616 (70.5%) | Ratio: 1.01x\n",
            "Epoch  50 | Bob: 1.401 (68.6%) | Eve: 1.584 (67.0%) | Ratio: 1.13x\n",
            "Epoch  60 | Bob: 1.633 (67.4%) | Eve: 1.690 (67.4%) | Ratio: 1.03x\n",
            "Epoch  70 | Bob: 1.509 (64.1%) | Eve: 1.875 (63.9%) | Ratio: 1.24x\n",
            "Epoch  80 | Bob: 1.399 (66.6%) | Eve: 1.783 (65.4%) | Ratio: 1.27x\n",
            "Epoch  90 | Bob: 1.136 (70.5%) | Eve: 1.711 (65.4%) | Ratio: 1.51x\n",
            "\n",
            "✓ Phase 2 Complete!\n",
            "\n",
            "======================================================================\n",
            "FINAL EVALUATION\n",
            "======================================================================\n",
            "\n",
            "Original:  'Hello World!'\n",
            "Bob:       'selloorllls' (60.9%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: Avg 5.8% similarity\n",
            "\n",
            "Original:  'This is a test.'\n",
            "Bob:       'i.i..lesl.l' (38.5%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: Avg 2.8% similarity\n",
            "\n",
            "Original:  'Secret message here.'\n",
            "Bob:       'lelre' (24.0%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: Avg 4.0% similarity\n",
            "\n",
            "Original:  'Encryption works!'\n",
            "Bob:       'lllresliosorlsl' (37.5%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: Avg 0.0% similarity\n",
            "\n",
            "Original:  'Neural crypto system.'\n",
            "Bob:       'lesr.llreslo.esles.l' (39.0%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: Avg 11.8% similarity\n",
            "\n",
            "Original:  'Testing ABC 123.'\n",
            "Bob:       'e.li' (20.0%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: Avg 1.7% similarity\n",
            "\n",
            "Original:  'Quick brown fox.'\n",
            "Bob:       'ssillrolloe.l' (34.5%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: Avg 17.7% similarity\n",
            "\n",
            "Original:  'The lazy dog jumps.'\n",
            "Bob:       'el.lelollsss..l' (29.4%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: Avg 11.1% similarity\n",
            "\n",
            "Original:  'Machine learning is powerful.'\n",
            "Bob:       'l.lillll.rlilli.soerlsl.l' (40.7%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: Avg 6.5% similarity\n",
            "\n",
            "Original:  'Deep neural networks.'\n",
            "Bob:       'see.le.r.e' (32.3%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: Avg 4.7% similarity\n",
            "\n",
            "======================================================================\n",
            "DETAILED METRICS\n",
            "======================================================================\n",
            "Bob Similarity:      35.7% ✗\n",
            "Bob Char Accuracy:   11.6%\n",
            "Eve Similarity:      0.0% ✓\n",
            "Key Sensitivity:     93.4% ✓\n",
            "Security Ratio:      35.67x ✓\n",
            "\n",
            "======================================================================\n",
            "ANALYSIS\n",
            "======================================================================\n",
            "✗ Bob: Needs improvement\n",
            "✓ Eve: Completely unable to break encryption\n",
            "✓ Keys: Highly sensitive - wrong keys produce garbage\n",
            "\n",
            "✗ OVERALL: System needs more training or architecture adjustment\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Keys now matter (93% sensitivity - GOOD!)\n",
        "\n",
        "❌ But Bob can't decrypt anymore (35% vs 99% - TERRIBLE!)\n",
        "\n",
        "❌ Phase 2 training is destroying what Phase 1 learned\n",
        "\n",
        "**Root Cause: Adversarial Training Too Strong**\n",
        "\n",
        "The aggressive adversarial training (5x Eve + 2x Alice adversarial + stronger key mixing) is destroying Bob's ability to decrypt. It's like:\n",
        "- Phase 1: Learn to ride a bike ✓\n",
        "- Phase 2: Someone kicks you off while you're riding ✗\n"
      ],
      "metadata": {
        "id": "i5NXUxSeo7y_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "MINIMAL FIX VERSION\n",
        "Strategy: Keep the original working system, just tweak key sensitivity\n",
        "Don't break what's already working!\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from difflib import SequenceMatcher\n",
        "import hashlib\n",
        "\n",
        "# ============ String Processor (UNCHANGED) ============\n",
        "class StringProcessor:\n",
        "    def __init__(self, max_len=64):\n",
        "        self.max_len = max_len\n",
        "        chars = ' abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789.,!?-'\n",
        "        self.vocab = {c: i for i, c in enumerate(chars)}\n",
        "        self.vocab['<PAD>'] = len(self.vocab)\n",
        "        self.vocab['<END>'] = len(self.vocab)\n",
        "        self.inv_vocab = {v: k for k, v in self.vocab.items()}\n",
        "        self.vocab_size = len(self.vocab)\n",
        "\n",
        "    def encode(self, text):\n",
        "        ids = [self.vocab.get(c, 0) for c in text[:self.max_len-1]]\n",
        "        ids.append(self.vocab['<END>'])\n",
        "        while len(ids) < self.max_len:\n",
        "            ids.append(self.vocab['<PAD>'])\n",
        "        return torch.LongTensor(ids)\n",
        "\n",
        "    def decode(self, ids):\n",
        "        chars = []\n",
        "        for i in ids:\n",
        "            c = self.inv_vocab.get(int(i), '')\n",
        "            if c == '<END>':\n",
        "                break\n",
        "            if c != '<PAD>':\n",
        "                chars.append(c)\n",
        "        return ''.join(chars)\n",
        "\n",
        "    def batch_encode(self, texts):\n",
        "        return torch.stack([self.encode(t) for t in texts])\n",
        "\n",
        "\n",
        "# ============ Autoencoder (UNCHANGED) ============\n",
        "class CryptoAutoencoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=128, hidden_dim=256):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=vocab_size-2)\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(embed_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, embed_dim)\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(embed_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, vocab_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, tokens, return_embeddings=False):\n",
        "        emb = self.embedding(tokens)\n",
        "        enc = self.encoder(emb)\n",
        "\n",
        "        if return_embeddings:\n",
        "            return enc\n",
        "\n",
        "        logits = self.decoder(enc)\n",
        "        return logits\n",
        "\n",
        "\n",
        "# ============ Key Generator (UNCHANGED) ============\n",
        "class KeyGenerator:\n",
        "    @staticmethod\n",
        "    def generate_from_message(message, key_size=128):\n",
        "        msg_hash = hashlib.sha256(message.encode()).hexdigest()\n",
        "        seed = int(msg_hash[:8], 16)\n",
        "        np.random.seed(seed)\n",
        "        key = torch.FloatTensor(np.random.randn(key_size))\n",
        "        return key\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_random(key_size=128):\n",
        "        return torch.randn(key_size)\n",
        "\n",
        "\n",
        "# ============ TWEAKED: Slightly Stronger Key Layer ============\n",
        "class KeyDependentEncryption(nn.Module):\n",
        "    \"\"\"MINIMAL CHANGE: Just add one more nonlinearity\"\"\"\n",
        "    def __init__(self, embed_dim=128):\n",
        "        super().__init__()\n",
        "        # Original transform + one extra layer\n",
        "        self.key_transform = nn.Sequential(\n",
        "            nn.Linear(embed_dim, embed_dim * 2),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(embed_dim * 2, embed_dim),\n",
        "            nn.Tanh()  # Extra nonlinearity\n",
        "        )\n",
        "\n",
        "        self.encrypt_mix = nn.Sequential(\n",
        "            nn.Linear(embed_dim * 2, embed_dim),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def encrypt(self, embeddings, key):\n",
        "        if len(key.shape) == 1:\n",
        "            key = key.unsqueeze(0).expand(embeddings.size(0), -1)\n",
        "\n",
        "        key_features = self.key_transform(key)\n",
        "        key_expanded = key_features.unsqueeze(1).expand(-1, embeddings.size(1), -1)\n",
        "\n",
        "        combined = torch.cat([embeddings, key_expanded], dim=-1)\n",
        "        encrypted = self.encrypt_mix(combined)\n",
        "\n",
        "        # SLIGHT TWEAK: Multiply by 2 for stronger key effect\n",
        "        encrypted = encrypted * (1 + key_expanded * 2)\n",
        "\n",
        "        return encrypted\n",
        "\n",
        "    def decrypt(self, encrypted, key):\n",
        "        if len(key.shape) == 1:\n",
        "            key = key.unsqueeze(0).expand(encrypted.size(0), -1)\n",
        "\n",
        "        key_features = self.key_transform(key)\n",
        "        key_expanded = key_features.unsqueeze(1).expand(-1, encrypted.size(1), -1)\n",
        "\n",
        "        # Reverse with same factor\n",
        "        decrypted = encrypted / (1 + key_expanded * 2 + 1e-8)\n",
        "\n",
        "        return decrypted\n",
        "\n",
        "\n",
        "# ============ Eve (UNCHANGED) ============\n",
        "class EveAttacker(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=128):\n",
        "        super().__init__()\n",
        "        self.attack_network = nn.Sequential(\n",
        "            nn.Linear(embed_dim, embed_dim * 2),\n",
        "            nn.LayerNorm(embed_dim * 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(embed_dim * 2, embed_dim * 2),\n",
        "            nn.LayerNorm(embed_dim * 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(embed_dim * 2, embed_dim),\n",
        "            nn.LayerNorm(embed_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(embed_dim, vocab_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, encrypted_embeddings):\n",
        "        return self.attack_network(encrypted_embeddings)\n",
        "\n",
        "\n",
        "# ============ CRITICAL FIX: Gentler Phase 2 Training ============\n",
        "class NeuralCryptoSystem:\n",
        "    def __init__(self, vocab_size, embed_dim=128, device='cuda'):\n",
        "        self.device = device\n",
        "        self.processor = StringProcessor()\n",
        "\n",
        "        self.autoencoder = CryptoAutoencoder(vocab_size, embed_dim).to(device)\n",
        "        self.crypto_layer = KeyDependentEncryption(embed_dim).to(device)\n",
        "        self.eve = EveAttacker(vocab_size, embed_dim).to(device)\n",
        "\n",
        "        self.opt_main = optim.Adam(\n",
        "            list(self.autoencoder.parameters()) + list(self.crypto_layer.parameters()),\n",
        "            lr=0.001\n",
        "        )\n",
        "        self.opt_eve = optim.Adam(self.eve.parameters(), lr=0.0005)\n",
        "\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    def train_phase1_reconstruction(self, messages, epochs=200):\n",
        "        \"\"\"UNCHANGED - This works perfectly\"\"\"\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"PHASE 1: RECONSTRUCTION TRAINING (NO ENCRYPTION)\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            total_loss = 0\n",
        "            total_acc = 0\n",
        "\n",
        "            for msg in messages:\n",
        "                tokens = self.processor.encode(msg).unsqueeze(0).to(self.device)\n",
        "\n",
        "                self.opt_main.zero_grad()\n",
        "                logits = self.autoencoder(tokens)\n",
        "\n",
        "                loss = self.criterion(logits.view(-1, logits.size(-1)), tokens.view(-1))\n",
        "                loss.backward()\n",
        "                self.opt_main.step()\n",
        "\n",
        "                pred = torch.argmax(logits, dim=-1)\n",
        "                acc = (pred == tokens).float().mean().item()\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                total_acc += acc\n",
        "\n",
        "            if epoch % 20 == 0:\n",
        "                avg_acc = total_acc / len(messages)\n",
        "                print(f\"Epoch {epoch:3d} | Loss: {total_loss/len(messages):.4f} | Acc: {avg_acc*100:.1f}%\")\n",
        "\n",
        "        final_acc = total_acc / len(messages)\n",
        "        print(f\"\\n✓ Phase 1 Complete! Accuracy: {final_acc*100:.1f}%\")\n",
        "        return final_acc > 0.95\n",
        "\n",
        "    def train_phase2_with_encryption(self, messages, epochs=100):\n",
        "        \"\"\"\n",
        "        CRITICAL FIX: Gentle training that preserves Phase 1 learning\n",
        "        - Keep original training intensity\n",
        "        - Just add small adversarial component\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"PHASE 2: GENTLE ENCRYPTION TRAINING\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            batch_msgs = np.random.choice(messages, min(8, len(messages)), replace=True)\n",
        "            tokens = self.processor.batch_encode(batch_msgs).to(self.device)\n",
        "\n",
        "            keys = torch.stack([KeyGenerator.generate_random(128) for _ in batch_msgs]).to(self.device)\n",
        "\n",
        "            # === Train Alice+Bob (ORIGINAL intensity) ===\n",
        "            self.opt_main.zero_grad()\n",
        "\n",
        "            embeddings = self.autoencoder(tokens, return_embeddings=True)\n",
        "            encrypted = self.crypto_layer.encrypt(embeddings, keys)\n",
        "            decrypted = self.crypto_layer.decrypt(encrypted, keys)\n",
        "            logits = self.autoencoder.decoder(decrypted)\n",
        "\n",
        "            loss_reconstruction = self.criterion(logits.view(-1, logits.size(-1)), tokens.view(-1))\n",
        "            loss_reconstruction.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(self.autoencoder.parameters(), 1.0)\n",
        "            torch.nn.utils.clip_grad_norm_(self.crypto_layer.parameters(), 1.0)\n",
        "            self.opt_main.step()\n",
        "\n",
        "            # === Train Eve (ORIGINAL intensity) ===\n",
        "            self.opt_eve.zero_grad()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                embeddings = self.autoencoder(tokens, return_embeddings=True)\n",
        "                encrypted = self.crypto_layer.encrypt(embeddings, keys)\n",
        "\n",
        "            eve_logits = self.eve(encrypted)\n",
        "            loss_eve = self.criterion(eve_logits.view(-1, eve_logits.size(-1)), tokens.view(-1))\n",
        "            loss_eve.backward()\n",
        "            self.opt_eve.step()\n",
        "\n",
        "            # === MINIMAL Adversarial (only after epoch 30) ===\n",
        "            if epoch > 30:  # Wait until Bob is stable!\n",
        "                self.opt_main.zero_grad()\n",
        "\n",
        "                embeddings = self.autoencoder(tokens, return_embeddings=True)\n",
        "                encrypted = self.crypto_layer.encrypt(embeddings, keys)\n",
        "                eve_attack = self.eve(encrypted)\n",
        "\n",
        "                loss_adversarial = -self.criterion(eve_attack.view(-1, eve_attack.size(-1)), tokens.view(-1))\n",
        "                (loss_adversarial * 0.1).backward()  # VERY SMALL weight!\n",
        "                self.opt_main.step()\n",
        "\n",
        "            if epoch % 10 == 0:\n",
        "                bob_pred = torch.argmax(logits, dim=-1)\n",
        "                eve_pred = torch.argmax(eve_logits, dim=-1)\n",
        "\n",
        "                bob_acc = (bob_pred == tokens).float().mean().item()\n",
        "                eve_acc = (eve_pred == tokens).float().mean().item()\n",
        "                ratio = loss_eve.item() / (loss_reconstruction.item() + 1e-8)\n",
        "\n",
        "                print(f\"Epoch {epoch:3d} | Bob: {loss_reconstruction.item():.3f} ({bob_acc*100:.1f}%) | \"\n",
        "                      f\"Eve: {loss_eve.item():.3f} ({eve_acc*100:.1f}%) | Ratio: {ratio:.2f}x\")\n",
        "\n",
        "        print(\"\\n✓ Phase 2 Complete!\")\n",
        "\n",
        "    def encrypt_message(self, message, key=None):\n",
        "        if key is None:\n",
        "            key = KeyGenerator.generate_from_message(message, 128)\n",
        "\n",
        "        tokens = self.processor.encode(message).unsqueeze(0).to(self.device)\n",
        "        key = key.to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            embeddings = self.autoencoder(tokens, return_embeddings=True)\n",
        "            encrypted = self.crypto_layer.encrypt(embeddings, key)\n",
        "\n",
        "        return encrypted, key\n",
        "\n",
        "    def decrypt_message(self, encrypted, key):\n",
        "        key = key.to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            decrypted = self.crypto_layer.decrypt(encrypted, key)\n",
        "            logits = self.autoencoder.decoder(decrypted)\n",
        "            tokens = torch.argmax(logits, dim=-1)\n",
        "            message = self.processor.decode(tokens[0])\n",
        "\n",
        "        return message\n",
        "\n",
        "    def eve_attack(self, encrypted):\n",
        "        with torch.no_grad():\n",
        "            logits = self.eve(encrypted)\n",
        "            tokens = torch.argmax(logits, dim=-1)\n",
        "            message = self.processor.decode(tokens[0])\n",
        "\n",
        "        return message\n",
        "\n",
        "    def evaluate(self, test_messages):\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"FINAL EVALUATION\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        bob_sims = []\n",
        "        eve_sims = []\n",
        "        key_sens = []\n",
        "\n",
        "        for msg in test_messages[:10]:\n",
        "            encrypted, correct_key = self.encrypt_message(msg)\n",
        "\n",
        "            bob_msg = self.decrypt_message(encrypted, correct_key)\n",
        "            eve_msg = self.eve_attack(encrypted)\n",
        "\n",
        "            wrong_sims = []\n",
        "            for _ in range(3):\n",
        "                wrong_key = KeyGenerator.generate_random(128)\n",
        "                wrong_msg = self.decrypt_message(encrypted, wrong_key)\n",
        "                wrong_sims.append(SequenceMatcher(None, msg, wrong_msg).ratio())\n",
        "\n",
        "            bob_sim = SequenceMatcher(None, msg, bob_msg).ratio()\n",
        "            eve_sim = SequenceMatcher(None, msg, eve_msg).ratio()\n",
        "            avg_wrong = np.mean(wrong_sims)\n",
        "\n",
        "            bob_sims.append(bob_sim)\n",
        "            eve_sims.append(eve_sim)\n",
        "            key_sens.append(1 - avg_wrong)\n",
        "\n",
        "            print(f\"\\nOriginal:  '{msg}'\")\n",
        "            print(f\"Bob:       '{bob_msg}' ({bob_sim*100:.1f}%)\")\n",
        "            print(f\"Eve:       '{eve_msg}' ({eve_sim*100:.1f}%)\")\n",
        "            print(f\"Wrong key: Avg {avg_wrong*100:.1f}% similarity\")\n",
        "\n",
        "        avg_bob = np.mean(bob_sims)\n",
        "        avg_eve = np.mean(eve_sims)\n",
        "        avg_key_sens = np.mean(key_sens)\n",
        "        security_ratio = avg_bob / max(avg_eve, 0.01)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"FINAL METRICS\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\"Bob Similarity:    {avg_bob*100:.1f}% {'✓' if avg_bob > 0.90 else '✗'}\")\n",
        "        print(f\"Eve Similarity:    {avg_eve*100:.1f}% {'✓' if avg_eve < 0.30 else '⚠️'}\")\n",
        "        print(f\"Key Sensitivity:   {avg_key_sens*100:.1f}% {'✓' if avg_key_sens > 0.50 else '⚠️'}\")\n",
        "        print(f\"Security Ratio:    {security_ratio:.2f}x {'✓' if security_ratio > 3.0 else '⚠️'}\")\n",
        "\n",
        "        if avg_bob > 0.90:\n",
        "            print(\"\\n✓ Bob: EXCELLENT decryption!\")\n",
        "        if avg_eve < 0.20:\n",
        "            print(\"✓ Eve: CANNOT break encryption!\")\n",
        "        if avg_key_sens > 0.60:\n",
        "            print(\"✓ Keys: Good sensitivity!\")\n",
        "\n",
        "        if avg_bob > 0.90 and security_ratio > 3:\n",
        "            print(\"\\n🎉 SUCCESS! System works well!\")\n",
        "\n",
        "        print(\"=\"*70)\n",
        "\n",
        "\n",
        "# ============ Dataset ============\n",
        "LARGE_DATASET = [\n",
        "    \"Hello World!\", \"This is a test.\", \"Secret message here.\",\n",
        "    \"Encryption works!\", \"Neural crypto system.\", \"Testing ABC 123.\",\n",
        "    \"Quick brown fox.\", \"The lazy dog jumps.\",\n",
        "    \"Machine learning is powerful.\", \"Deep neural networks.\", \"Artificial intelligence evolves.\",\n",
        "    \"Natural language processing.\", \"Computer vision tasks.\", \"Reinforcement learning agent.\",\n",
        "    \"Gradient descent optimizer.\", \"Backpropagation algorithm.\", \"Model accuracy improves.\",\n",
        "    \"Training loss decreases.\", \"Validation metrics good.\", \"Test results excellent.\",\n",
        "    \"Good morning everyone.\", \"How are you today?\", \"See you tomorrow.\",\n",
        "    \"Thank you very much.\", \"Great job well done.\", \"Nice work keep going.\",\n",
        "    \"Data science project.\", \"Python programming fun.\", \"Code quality matters.\",\n",
        "    \"Documentation complete.\", \"Production ready now.\", \"System performance optimal.\",\n",
        "    \"Hi there!\", \"Goodbye!\", \"Yes indeed.\", \"No problem.\", \"Of course.\",\n",
        "    \"Absolutely right.\", \"Definitely true.\", \"Maybe later.\", \"Not now.\", \"Soon enough.\",\n",
        "    \"The sun rises early.\", \"Birds sing beautifully.\", \"Rivers flow downstream.\",\n",
        "    \"Mountains stand tall.\", \"Oceans are deep.\", \"Stars shine bright.\",\n",
        "    \"Music sounds wonderful.\", \"Books tell stories.\", \"Art inspires people.\",\n",
        "    \"Science explains nature.\", \"Math solves problems.\", \"History teaches lessons.\",\n",
        "]\n",
        "\n",
        "\n",
        "# ============ Main ============\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Device: {device}\")\n",
        "    print(f\"Dataset: {len(LARGE_DATASET)} messages\\n\")\n",
        "\n",
        "    processor = StringProcessor()\n",
        "    system = NeuralCryptoSystem(processor.vocab_size, embed_dim=128, device=device)\n",
        "\n",
        "    success = system.train_phase1_reconstruction(LARGE_DATASET, epochs=200)\n",
        "\n",
        "    if success:\n",
        "        system.train_phase2_with_encryption(LARGE_DATASET, epochs=100)\n",
        "        system.evaluate(LARGE_DATASET)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvN0vvRkn3K2",
        "outputId": "b6d054a5-76f1-4ddb-89e9-d4266dd5dc16"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n",
            "Dataset: 54 messages\n",
            "\n",
            "\n",
            "======================================================================\n",
            "PHASE 1: RECONSTRUCTION TRAINING (NO ENCRYPTION)\n",
            "======================================================================\n",
            "Epoch   0 | Loss: 0.6372 | Acc: 89.0%\n",
            "Epoch  20 | Loss: 0.0002 | Acc: 100.0%\n",
            "Epoch  40 | Loss: 0.0001 | Acc: 100.0%\n",
            "Epoch  60 | Loss: 0.0000 | Acc: 100.0%\n",
            "Epoch  80 | Loss: 0.0000 | Acc: 100.0%\n",
            "Epoch 100 | Loss: 0.0000 | Acc: 100.0%\n",
            "Epoch 120 | Loss: 0.0000 | Acc: 100.0%\n",
            "Epoch 140 | Loss: 0.0000 | Acc: 100.0%\n",
            "Epoch 160 | Loss: 0.0000 | Acc: 100.0%\n",
            "Epoch 180 | Loss: 0.0000 | Acc: 100.0%\n",
            "\n",
            "✓ Phase 1 Complete! Accuracy: 100.0%\n",
            "\n",
            "======================================================================\n",
            "PHASE 2: GENTLE ENCRYPTION TRAINING\n",
            "======================================================================\n",
            "Epoch   0 | Bob: 2.890 (56.6%) | Eve: 4.318 (0.6%) | Ratio: 1.49x\n",
            "Epoch  10 | Bob: 0.011 (100.0%) | Eve: 2.146 (75.8%) | Ratio: 190.39x\n",
            "Epoch  20 | Bob: 0.011 (100.0%) | Eve: 1.319 (87.1%) | Ratio: 115.58x\n",
            "Epoch  30 | Bob: 0.005 (99.8%) | Eve: 1.062 (88.7%) | Ratio: 194.94x\n",
            "Epoch  40 | Bob: 0.115 (99.6%) | Eve: 4.260 (16.4%) | Ratio: 37.09x\n",
            "Epoch  50 | Bob: 0.011 (99.6%) | Eve: 1.781 (69.5%) | Ratio: 165.37x\n",
            "Epoch  60 | Bob: 0.007 (99.8%) | Eve: 1.671 (67.4%) | Ratio: 223.56x\n",
            "Epoch  70 | Bob: 0.002 (100.0%) | Eve: 1.817 (63.9%) | Ratio: 950.53x\n",
            "Epoch  80 | Bob: 0.002 (100.0%) | Eve: 1.697 (65.4%) | Ratio: 1129.28x\n",
            "Epoch  90 | Bob: 0.001 (100.0%) | Eve: 1.703 (65.4%) | Ratio: 1367.95x\n",
            "\n",
            "✓ Phase 2 Complete!\n",
            "\n",
            "======================================================================\n",
            "FINAL EVALUATION\n",
            "======================================================================\n",
            "\n",
            "Original:  'Hello World!'\n",
            "Bob:       'Hello World!' (100.0%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: Avg 9.9% similarity\n",
            "\n",
            "Original:  'This is a test.'\n",
            "Bob:       'This is a test.' (100.0%)\n",
            "Eve:       'ot' (11.8%)\n",
            "Wrong key: Avg 17.9% similarity\n",
            "\n",
            "Original:  'Secret message here.'\n",
            "Bob:       'pecret message here.' (95.0%)\n",
            "Eve:       'n' (0.0%)\n",
            "Wrong key: Avg 5.6% similarity\n",
            "\n",
            "Original:  'Encryption works!'\n",
            "Bob:       'Encryption works!' (100.0%)\n",
            "Eve:       'to ' (30.0%)\n",
            "Wrong key: Avg 13.5% similarity\n",
            "\n",
            "Original:  'Neural crypto system.'\n",
            "Bob:       'Neural crypto system.' (100.0%)\n",
            "Eve:       'tot' (25.0%)\n",
            "Wrong key: Avg 9.6% similarity\n",
            "\n",
            "Original:  'Testing ABC 123.'\n",
            "Bob:       'Testing ABC p23.' (93.8%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: Avg 19.8% similarity\n",
            "\n",
            "Original:  'Quick brown fox.'\n",
            "Bob:       'Quick brown fox.' (100.0%)\n",
            "Eve:       'o' (11.8%)\n",
            "Wrong key: Avg 6.7% similarity\n",
            "\n",
            "Original:  'The lazy dog jumps.'\n",
            "Bob:       'The lazy dog jumps.' (100.0%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: Avg 9.0% similarity\n",
            "\n",
            "Original:  'Machine learning is powerful.'\n",
            "Bob:       'Machine learning is powerful.' (100.0%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: Avg 29.8% similarity\n",
            "\n",
            "Original:  'Deep neural networks.'\n",
            "Bob:       'Deep neural networks.' (100.0%)\n",
            "Eve:       '' (0.0%)\n",
            "Wrong key: Avg 9.0% similarity\n",
            "\n",
            "======================================================================\n",
            "FINAL METRICS\n",
            "======================================================================\n",
            "Bob Similarity:    98.9% ✓\n",
            "Eve Similarity:    7.9% ✓\n",
            "Key Sensitivity:   86.9% ✓\n",
            "Security Ratio:    12.59x ✓\n",
            "\n",
            "✓ Bob: EXCELLENT decryption!\n",
            "✓ Eve: CANNOT break encryption!\n",
            "✓ Keys: Good sensitivity!\n",
            "\n",
            "🎉 SUCCESS! System works well!\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GeGQW3c_u6lV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}