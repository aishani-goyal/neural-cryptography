{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqnpbuZa9dL3",
        "outputId": "3b16acca-f6ff-4440-a6ab-29a3ca5ac421"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "ENHANCED DCGAN KEY GENERATOR - STRING SUPPORT\n",
            "======================================================================\n",
            "\n",
            "Original message: 'Hello, this is a secret message!'\n",
            "Tensor shape: torch.Size([256])\n",
            "\n",
            "Key generation complete:\n",
            "  Base key size: 64 bytes\n",
            "  Number of key sequences: 8\n",
            "  Each sequence length: 256\n",
            "  Message hash: b17bc84328a21850\n",
            "  Key space: 2^440 combinations\n",
            "\n",
            "Recovered message: 'Hello, this is a secret message!'\n",
            "Match: True\n",
            "\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import hashlib\n",
        "from datetime import datetime\n",
        "\n",
        "# ============ DCGAN Architecture (Same as before) ============\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, nz=100, ngf=64, nc=3):\n",
        "        super(Generator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.main(x)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, nc=3, ndf=64):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.main(x).view(-1, 1).squeeze(1)\n",
        "\n",
        "\n",
        "# ============ Enhanced Chaotic Map ============\n",
        "class EnhancedChaoticKeyGenerator:\n",
        "    def __init__(self, initial_seed=0.123456789, r=3.99):\n",
        "        self.x = initial_seed\n",
        "        self.r = r\n",
        "\n",
        "    def logistic_map(self, x):\n",
        "        \"\"\"Logistic map: x_{n+1} = r * x_n * (1 - x_n)\"\"\"\n",
        "        return (self.r * x * (1 - x)) % 1.0\n",
        "\n",
        "    def tent_map(self, x):\n",
        "        \"\"\"Tent map for additional chaos\"\"\"\n",
        "        return 2 * x if x < 0.5 else 2 * (1 - x)\n",
        "\n",
        "    def generate_sequence(self, length):\n",
        "        \"\"\"Generate chaotic sequence with higher complexity\"\"\"\n",
        "        sequence = []\n",
        "        for _ in range(length):\n",
        "            # Alternate between maps for more chaos\n",
        "            self.x = self.logistic_map(self.x)\n",
        "            self.x = self.tent_map(self.x)\n",
        "            sequence.append(self.x)\n",
        "        return np.array(sequence)\n",
        "\n",
        "    def generate_key_sequences(self, num_sequences=8, seq_length=512):\n",
        "        \"\"\"Generate multiple independent chaotic key sequences\"\"\"\n",
        "        keys = []\n",
        "        for i in range(num_sequences):\n",
        "            # Different initial conditions for each sequence\n",
        "            self.x = (self.x + 0.123 * (i + 1)) % 1.0\n",
        "            key_seq = self.generate_sequence(seq_length)\n",
        "            keys.append(key_seq)\n",
        "        return keys\n",
        "\n",
        "\n",
        "# ============ Enhanced DCGAN Key Generator ============\n",
        "class EnhancedDCGANKeyGenerator:\n",
        "    def __init__(self, nz=100, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
        "        self.device = device\n",
        "        self.nz = nz\n",
        "        self.generator = Generator(nz=nz).to(device)\n",
        "        self.chaotic_gen = EnhancedChaoticKeyGenerator()\n",
        "\n",
        "    def load_pretrained(self, path):\n",
        "        \"\"\"Load pre-trained DCGAN generator\"\"\"\n",
        "        self.generator.load_state_dict(torch.load(path, map_location=self.device))\n",
        "        self.generator.eval()\n",
        "\n",
        "    def generate_key_image(self, noise=None):\n",
        "        \"\"\"Generate synthetic image using DCGAN\"\"\"\n",
        "        if noise is None:\n",
        "            noise = torch.randn(1, self.nz, 1, 1, device=self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            fake_image = self.generator(noise)\n",
        "\n",
        "        return fake_image\n",
        "\n",
        "    def extract_base_key(self, image_tensor, timestamp=None, nonce=None, message_hash=None):\n",
        "        \"\"\"\n",
        "        Enhanced key extraction with message hash integration\n",
        "        \"\"\"\n",
        "        img_np = image_tensor.cpu().numpy().squeeze()\n",
        "        pixel_sum = np.sum(img_np, axis=(0, 1, 2))\n",
        "\n",
        "        if timestamp is None:\n",
        "            timestamp = datetime.now().timestamp()\n",
        "\n",
        "        if nonce is None:\n",
        "            nonce = np.random.randint(0, 2**32)\n",
        "\n",
        "        # Integrate message hash for message-specific keys\n",
        "        if message_hash is None:\n",
        "            message_hash = \"\"\n",
        "\n",
        "        # Combine all components\n",
        "        key_data = f\"{pixel_sum}_{timestamp}_{nonce}_{message_hash}\".encode()\n",
        "\n",
        "        # Generate SHA-512 hash\n",
        "        base_key = hashlib.sha512(key_data).digest()\n",
        "\n",
        "        return base_key, timestamp, nonce\n",
        "\n",
        "    def generate_encryption_keys(self, seq_length=512, message=None):\n",
        "        \"\"\"\n",
        "        Complete key generation pipeline with message awareness\n",
        "        \"\"\"\n",
        "        # Generate message hash if provided\n",
        "        message_hash = None\n",
        "        if message is not None:\n",
        "            if isinstance(message, str):\n",
        "                message_hash = hashlib.sha256(message.encode()).hexdigest()[:16]\n",
        "            elif isinstance(message, torch.Tensor):\n",
        "                message_hash = hashlib.sha256(message.cpu().numpy().tobytes()).hexdigest()[:16]\n",
        "\n",
        "        # Generate DCGAN image\n",
        "        noise = torch.randn(1, self.nz, 1, 1, device=self.device)\n",
        "        key_image = self.generate_key_image(noise)\n",
        "\n",
        "        # Extract base key with message hash\n",
        "        base_key, timestamp, nonce = self.extract_base_key(key_image, message_hash=message_hash)\n",
        "\n",
        "        # Initialize chaotic generator with base key\n",
        "        seed = int.from_bytes(base_key[:8], byteorder='big') / (2**64)\n",
        "        self.chaotic_gen.x = seed\n",
        "\n",
        "        # Generate 8 chaotic key sequences\n",
        "        key_sequences = self.chaotic_gen.generate_key_sequences(\n",
        "            num_sequences=8,\n",
        "            seq_length=seq_length\n",
        "        )\n",
        "\n",
        "        # Convert to tensors for easier use\n",
        "        key_tensors = [torch.FloatTensor(ks).to(self.device) for ks in key_sequences]\n",
        "\n",
        "        return {\n",
        "            'base_key': base_key,\n",
        "            'key_sequences': key_sequences,\n",
        "            'key_tensors': key_tensors,\n",
        "            'timestamp': timestamp,\n",
        "            'nonce': nonce,\n",
        "            'key_image': key_image,\n",
        "            'noise': noise,\n",
        "            'message_hash': message_hash\n",
        "        }\n",
        "\n",
        "\n",
        "# ============ String Preprocessing Utilities ============\n",
        "class StringPreprocessor:\n",
        "    \"\"\"Convert strings to tensor format and back\"\"\"\n",
        "\n",
        "    def __init__(self, max_length=512):\n",
        "        self.max_length = max_length\n",
        "        self.pad_token = 0\n",
        "        self.start_token = 1\n",
        "        self.end_token = 2\n",
        "\n",
        "    def string_to_tensor(self, text):\n",
        "        \"\"\"Convert string to integer tensor (ASCII values)\"\"\"\n",
        "        # Convert to ASCII values\n",
        "        ascii_vals = [ord(c) for c in text]\n",
        "\n",
        "        # Add start and end tokens\n",
        "        tokens = [self.start_token] + ascii_vals + [self.end_token]\n",
        "\n",
        "        # Pad or truncate\n",
        "        if len(tokens) < self.max_length:\n",
        "            tokens = tokens + [self.pad_token] * (self.max_length - len(tokens))\n",
        "        else:\n",
        "            tokens = tokens[:self.max_length-1] + [self.end_token]\n",
        "\n",
        "        return torch.LongTensor(tokens)\n",
        "\n",
        "    def tensor_to_string(self, tensor):\n",
        "        \"\"\"Convert integer tensor back to string\"\"\"\n",
        "        # Remove padding and special tokens\n",
        "        tokens = tensor.cpu().numpy()\n",
        "\n",
        "        # Find end token\n",
        "        try:\n",
        "            end_idx = np.where(tokens == self.end_token)[0][0]\n",
        "            tokens = tokens[1:end_idx]  # Remove start and end tokens\n",
        "        except:\n",
        "            tokens = tokens[1:]  # Just remove start token\n",
        "\n",
        "        # Remove padding\n",
        "        tokens = tokens[tokens != self.pad_token]\n",
        "\n",
        "        # Convert back to characters\n",
        "        try:\n",
        "            text = ''.join([chr(int(t)) for t in tokens if 0 < t < 128])\n",
        "        except:\n",
        "            text = \"\"\n",
        "\n",
        "        return text\n",
        "\n",
        "    def batch_strings_to_tensor(self, strings):\n",
        "        \"\"\"Convert batch of strings to tensor\"\"\"\n",
        "        return torch.stack([self.string_to_tensor(s) for s in strings])\n",
        "\n",
        "    def batch_tensor_to_strings(self, tensor):\n",
        "        \"\"\"Convert batch of tensors to strings\"\"\"\n",
        "        return [self.tensor_to_string(t) for t in tensor]\n",
        "\n",
        "\n",
        "# ============ Usage Example ============\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\"*70)\n",
        "    print(\"ENHANCED DCGAN KEY GENERATOR - STRING SUPPORT\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Initialize\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    key_gen = EnhancedDCGANKeyGenerator(device=device)\n",
        "    preprocessor = StringPreprocessor(max_length=256)\n",
        "\n",
        "    # Test with string\n",
        "    test_message = \"Hello, this is a secret message!\"\n",
        "    print(f\"\\nOriginal message: '{test_message}'\")\n",
        "\n",
        "    # Convert to tensor\n",
        "    message_tensor = preprocessor.string_to_tensor(test_message)\n",
        "    print(f\"Tensor shape: {message_tensor.shape}\")\n",
        "\n",
        "    # Generate keys for this message\n",
        "    keys = key_gen.generate_encryption_keys(\n",
        "        seq_length=256,\n",
        "        message=test_message\n",
        "    )\n",
        "\n",
        "    print(f\"\\nKey generation complete:\")\n",
        "    print(f\"  Base key size: {len(keys['base_key'])} bytes\")\n",
        "    print(f\"  Number of key sequences: {len(keys['key_sequences'])}\")\n",
        "    print(f\"  Each sequence length: {len(keys['key_sequences'][0])}\")\n",
        "    print(f\"  Message hash: {keys['message_hash']}\")\n",
        "    print(f\"  Key space: 2^440 combinations\")\n",
        "\n",
        "    # Test back conversion\n",
        "    recovered = preprocessor.tensor_to_string(message_tensor)\n",
        "    print(f\"\\nRecovered message: '{recovered}'\")\n",
        "    print(f\"Match: {recovered == test_message}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G6cYRZ829jGc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}